<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>删除重复文件的神器：dupeGuru - Linux.cn Archive</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="删除重复文件的神器：dupeGuru"><meta property="og:description" content="最近，我需要清理我父亲的文件和文件夹。有一个难题是，里面存在很多不正确的名字的重复文件。有移动硬盘的备份，同时还为同一个文件编辑了多个版本，甚至改变的目录结构，同一个文件被复制了好几次，名字改变，位置改变等，这些文件挤满了磁盘空间。追踪每一个文件成了一个最大的问题。万幸的是，有一个小巧的软件可以帮助你省下很多时间来找到删除你系统中重复的文件：dupeGuru。它用Python写成，这个去重软件几个小时前切换到了GPLv3许可证。因此是时候用它来清理你的文件了！  dupeGuru的安装 在Ubuntu上， 你可以加入如下硬编码的软"><meta property="og:type" content="article"><meta property="og:url" content="/article-4920-1.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2015-02-22T10:00:00+00:00"><meta property="article:modified_time" content="2015-02-22T10:00:00+00:00"><meta itemprop=name content="删除重复文件的神器：dupeGuru"><meta itemprop=description content="最近，我需要清理我父亲的文件和文件夹。有一个难题是，里面存在很多不正确的名字的重复文件。有移动硬盘的备份，同时还为同一个文件编辑了多个版本，甚至改变的目录结构，同一个文件被复制了好几次，名字改变，位置改变等，这些文件挤满了磁盘空间。追踪每一个文件成了一个最大的问题。万幸的是，有一个小巧的软件可以帮助你省下很多时间来找到删除你系统中重复的文件：dupeGuru。它用Python写成，这个去重软件几个小时前切换到了GPLv3许可证。因此是时候用它来清理你的文件了！  dupeGuru的安装 在Ubuntu上， 你可以加入如下硬编码的软"><meta itemprop=datePublished content="2015-02-22T10:00:00+00:00"><meta itemprop=dateModified content="2015-02-22T10:00:00+00:00"><meta itemprop=wordCount content="50"><meta itemprop=keywords content="dupeGuru,重复文件,删除,"><link rel=preconnect href=https://fonts.bunny.net crossorigin><link rel=dns-prefetch href=//fonts.bunny.net><link rel=dns-prefetch href=//fonts.bunny.net><link rel=stylesheet href="https://fonts.bunny.net/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Linux.cn Archive" rel=home><div class="logo__item logo__text"><div class=logo__title>Linux.cn Archive</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href=/categories/><span class=menu__text>Categories</span></a></li><li class=menu__item><a class=menu__link href=/tags/><span class=menu__text>Tags</span></a></li><li class=menu__item><a class=menu__link href><span class=menu__text>RSS</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>删除重复文件的神器：dupeGuru</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2015-02-22T10:00:00Z>February 22, 2015</time></div></div></header><div class="content post__content clearfix"><p>最近，我需要清理我父亲的文件和文件夹。有一个难题是，里面存在很多不正确的名字的重复文件。有移动硬盘的备份，同时还为同一个文件编辑了多个版本，甚至改变的目录结构，同一个文件被复制了好几次，名字改变，位置改变等，这些文件挤满了磁盘空间。追踪每一个文件成了一个最大的问题。万幸的是，有一个小巧的软件可以帮助你省下很多时间来找到删除你系统中重复的文件：<a href=http://www.hardcoded.net/dupeguru/>dupeGuru</a>。它用Python写成，这个去重软件几个小时前切换到了GPLv3许可证。因此是时候用它来清理你的文件了！</p><p><img src=/data/attachment/album/201502/21/230553ho4kveh8weiamxgv.png alt></p><h3 id=dupeguru的安装>dupeGuru的安装</h3><p>在Ubuntu上， 你可以加入如下硬编码的软件PPA：</p><pre tabindex=0><code>$ sudo apt-add-repository ppa:hsoft/ppa
$ sudo apt-get update 
</code></pre><p>接着用下面的命令安装：</p><pre tabindex=0><code>$ sudo apt-get install dupeguru-se 
</code></pre><p>在ArchLinux中，这个包在<a href=https://aur.archlinux.org/packages/dupeguru-se/>AUR</a>中。</p><p>如果你想自己编译，源码在<a href=https://github.com/hsoft/dupeguru>GitHub</a>上。</p><h3 id=dupeguru的基本使用>dupeGuru的基本使用</h3><p>DupeGuru的构想是既快又安全。这意味着程序不会在你的系统上疯狂地运行。它很少会删除你不想要删除的文件。然而，既然在讨论文件删除，保持谨慎和小心总是好的：备份总是需要的。</p><p>你看完注意事项后，你可以用下面的命令运行duprGuru了：</p><pre tabindex=0><code>$ dupeguru_se 
</code></pre><p>你应该看到要你选择文件夹的欢迎界面，在这里加入你你想要扫描的重复文件夹。</p><p><img src=/data/attachment/album/201502/21/230558msg2gyjrr992zqf9.jpg alt></p><p>一旦你选择完文件夹并启动扫描后，dupeFuru会以列表的形式显示重复文件的组：</p><p><img src=/data/attachment/album/201502/21/230600gi7hj4qn447wlzqt.jpg alt></p><p>注意的是默认上dupeGuru基于文件的内容匹配，而不是他们的名字。为了防止意外地删除了重要的文件，匹配列列出了其使用的匹配算法。在这里，你可以选择你想要删除的匹配文件，并按下“Action” 按钮来看到可用的操作。</p><p><img src=/data/attachment/album/201502/21/230605xcl25e2e7x44lxe2.jpg alt></p><p>可用的选项相当广泛。简而言之，你可以删除重复、移动到另外的位置、忽略它们、打开它们、重命名它们甚至用自定义命令运行它们。如果你希望删除重复文件，你可能会像我一样非常意外竟然有这么多种删除方式。</p><p><img src=/data/attachment/album/201502/21/230607zeerk34em96m23f6.jpg alt></p><p>你不仅可以将删除的文件移到垃圾箱或者永久删除，还可以选择留下指向原文件的链接（软链接或者硬链接）。也就是说，重复文件将会删除文件存储，但是会保留下一个指向原文件的链接。这将会省下大量的磁盘空间。如果你将这些文件导入到工作空间或者它们有一些依赖时很有用。</p><p>还有一个奇特的选项：你可以用HTML或者CSV文件导出结果。我不确定你会不会需要这么做，但是我假设你想追踪重复文件而不是想让dupeGuru处理它们时会有用。</p><p>最后但并不是最不重要的是，偏好菜单可以让你按照你的想法来操作去重这件事。</p><p><img src=/data/attachment/album/201502/21/230609ig10dumv0z0fub3g.jpg alt></p><p>这里你可以选择扫描的标准，基于内容还是基于名字，并且有一个阈值来控制结果的数量。这里同样可以定义自定义在执行中可以选择的命令。混在其他那些小的选项中，要注意的是dupeGuru默认忽略小于10KB的文件。</p><p>要了解更多的信息，我建议你到<a href=http://www.hardcoded.net/dupeguru/>官方网站</a>看下，这里有很多文档、论坛支持和其他好东西。</p><p>总结一下，dupeGuru是我无论何时准备备份或者释放空间时所想到的软件。我发现这对高级用户而言也足够强大了，对新人而言也很直观。锦上添花的是：dupeGuru是跨平台的，这意味着你可以在Mac或者在Windows PC上都可以使用。如果你有特定的需求，想要清理音乐或者图片。这里有两个变种：<a href=http://www.hardcoded.net/dupeguru_me/>dupeguru-me</a>和 <a href=http://www.hardcoded.net/dupeguru_pe/>dupeguru-pe</a>， 相应地可以清理音频和图片文件。与常规版本的不同是它不仅比较文件格式还比较特定的媒体数据像质量和码率。</p><p>你觉得dupeGuru怎么样？你会考虑使用它么？或者你有任何可以替代的软件的建议么？让我在评论区知道你们的想法。</p><hr><p>via: <a href=http://xmodulo.com/dupeguru-deduplicate-files-linux.html>http://xmodulo.com/dupeguru-deduplicate-files-linux.html</a></p><p>作者：<a href=http://xmodulo.com/author/adrien>Adrien Brochard</a> 译者：<a href=https://github.com/geekpi>geekpi</a> 校对：<a href=https://github.com/wxy>wxy</a></p><p>本文由 <a href=https://github.com/LCTT/TranslateProject>LCTT</a> 原创翻译，<a href=http://linux.cn/>Linux中国</a> 荣誉推出</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/dupeguru/ rel=tag>dupeGuru</a></li><li class=tags__item><a class="tags__link btn" href=/tags/%E9%87%8D%E5%A4%8D%E6%96%87%E4%BB%B6/ rel=tag>重复文件</a></li><li class=tags__item><a class="tags__link btn" href=/tags/%E5%88%A0%E9%99%A4/ rel=tag>删除</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Linux.cn Archive.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>