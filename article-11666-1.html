<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>怎样使用 awk 删掉文件中重复的行 - Linux.cn Archive</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="怎样使用 awk 删掉文件中重复的行"><meta property="og:description" content="学习怎样使用 awk 的 !visited++ 在不重新排序或改变原排列顺序的前提下删掉重复的行。"><meta property="og:type" content="article"><meta property="og:url" content="/article-11666-1.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-12-12T12:43:35+00:00"><meta property="article:modified_time" content="2019-12-12T12:43:35+00:00"><meta itemprop=name content="怎样使用 awk 删掉文件中重复的行"><meta itemprop=description content="学习怎样使用 awk 的 !visited++ 在不重新排序或改变原排列顺序的前提下删掉重复的行。"><meta itemprop=datePublished content="2019-12-12T12:43:35+00:00"><meta itemprop=dateModified content="2019-12-12T12:43:35+00:00"><meta itemprop=wordCount content="268"><meta itemprop=keywords content="awk,"><link rel=preconnect href=https://fonts.bunny.net crossorigin><link rel=dns-prefetch href=//fonts.bunny.net><link rel=dns-prefetch href=//fonts.bunny.net><link rel=stylesheet href="https://fonts.bunny.net/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Linux.cn Archive" rel=home><div class="logo__item logo__text"><div class=logo__title>Linux.cn Archive</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href=/categories/><span class=menu__text>Categories</span></a></li><li class=menu__item><a class=menu__link href=/tags/><span class=menu__text>Tags</span></a></li><li class=menu__item><a class=menu__link href><span class=menu__text>RSS</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>怎样使用 awk 删掉文件中重复的行</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-12-12T12:43:35Z>December 12, 2019</time></div></div></header><div class="content post__content clearfix"><blockquote><p>学习怎样使用 awk 的 <code>!visited[$0]++</code> 在不重新排序或改变原排列顺序的前提下删掉重复的行。</p></blockquote><p><img src=/data/attachment/album/201912/12/124322vwe3tq3wlw33tw1f.jpg alt></p><p>假设你有一个文本文件，你需要删掉所有重复的行。</p><h3 id=tldr>TL;DR</h3><p><em>要保持原来的排列顺序</em>删掉重复行，使用：</p><pre tabindex=0><code>awk &#39;!visited[$0]++&#39; your_file &gt; deduplicated_file
</code></pre><h3 id=工作原理>工作原理</h3><p>这个脚本维护一个关联数组，索引（键）为文件中去重后的行，每个索引对应的值为该行出现的次数。对于文件的每一行，如果这行（之前）出现的次数为 0，则值加 1，并打印这行，否则值加 1，不打印这行。</p><p>我之前不熟悉 <code>awk</code>，我想弄清楚这么短小的一个脚本是怎么实现的。我调研了下，下面是调研心得：</p><ul><li>这个 awk “脚本” <code>!visited[$0]++</code> 对输入文件的<em>每一行</em>都执行。</li><li><code>visited[]</code> 是一个<a href=http://kirste.userpage.fu-berlin.de/chemnet/use/info/gawk/gawk_12.html>关联数组</a>（又名<a href=https://en.wikipedia.org/wiki/Associative_array>映射</a>）类型的变量。<code>awk</code> 会在第一次执行时初始化它，因此我们不需要初始化。</li><li><code>$0</code> 变量的值是当前正在被处理的行的内容。</li><li><code>visited[$0]</code> 通过与 <code>$0</code>（正在被处理的行）相等的键来访问该映射中的值，即出现次数（我们在下面设置的）。</li><li><code>!</code> 对表示出现次数的值取反：<ul><li>在 <code>awk</code> 中，<a href=https://www.gnu.org/software/gawk/manual/html_node/Truth-Values.html>任意非零的数或任意非空的字符串的值是 <code>true</code></a>。</li><li><a href=https://ftp.gnu.org/old-gnu/Manuals/gawk-3.0.3/html_chapter/gawk_8.html>变量默认的初始值为空字符串</a>，如果被转换为数字，则为 0。</li><li>也就是说：<ul><li>如果 <code>visited[$0]</code> 的值是一个比 0 大的数，取反后被解析成 <code>false</code>。</li><li>如果 <code>visited[$0]</code> 的值为等于 0 的数字或空字符串，取反后被解析成 <code>true</code> 。</li></ul></li><li><code>++</code> 表示变量 <code>visited[$0]</code> 的值加 1。<ul><li>如果该值为空，<code>awk</code> 自动把它转换为 <code>0</code>（数字） 后加 1。</li><li>注意：加 1 操作是在我们取到了变量的值之后执行的。</li></ul></li></ul></li></ul><p>总的来说，整个表达式的意思是：</p><ul><li><code>true</code>：如果表示出现次数为 0 或空字符串</li><li><code>false</code>：如果出现的次数大于 0</li></ul><p><code>awk</code> 由 <a href=http://kirste.userpage.fu-berlin.de/chemnet/use/info/gawk/gawk_9.html>模式或表达式和一个与之关联的动作</a> 组成：</p><pre tabindex=0><code>&lt;模式/表达式&gt; { &lt;动作&gt; }
</code></pre><p>如果匹配到了模式，就会执行后面的动作。如果省略动作，<code>awk</code> 默认会打印（<code>print</code>）输入。</p><blockquote><p>省略动作等价于 <code>{print $0}</code>。</p></blockquote><p>我们的脚本由一个 <code>awk</code> 表达式语句组成，省略了动作。因此这样写：</p><pre tabindex=0><code>awk &#39;!visited[$0]++&#39; your_file &gt; deduplicated_file
</code></pre><p>等于这样写：</p><pre tabindex=0><code>awk &#39;!visited[$0]++ { print $0 }&#39; your_file &gt; deduplicated_file
</code></pre><p>对于文件的每一行，如果表达式匹配到了，这行内容被打印到输出。否则，不执行动作，不打印任何东西。</p><h3 id=为什么不用-uniq-命令>为什么不用 uniq 命令？</h3><p><code>uniq</code> 命令仅能对相邻的行去重。这是一个示例：</p><pre tabindex=0><code>$ cat test.txt
A
A
A
B
B
B
A
A
C
C
C
B
B
A
$ uniq &lt; test.txt
A
B
A
C
B
A
</code></pre><h3 id=其他方法>其他方法</h3><h4 id=使用-sort-命令>使用 sort 命令</h4><p>我们也可以用下面的 <a href=http://man7.org/linux/man-pages/man1/sort.1.html>sort</a> 命令来去除重复的行，但是<em>原来的行顺序没有被保留</em>。</p><pre tabindex=0><code>sort -u your_file &gt; sorted_deduplicated_file
</code></pre><h4 id=使用-cat--sort--cut>使用 cat + sort + cut</h4><p>上面的方法会产出一个去重的文件，各行是基于内容进行排序的。<a href=https://stackoverflow.com/a/20639730/2292448>通过管道连接命令</a>可以解决这个问题。</p><pre tabindex=0><code>cat -n your_file | sort -uk2 | sort -nk1 | cut -f2-
</code></pre><p><strong>工作原理</strong></p><p>假设我们有下面一个文件：</p><pre tabindex=0><code>abc
ghi
abc
def
xyz
def
ghi
klm
</code></pre><p><code>cat -n test.txt</code> 在每行前面显示序号：</p><pre tabindex=0><code>1       abc
2       ghi
3       abc
4       def
5       xyz
6       def
7       ghi
8       klm
</code></pre><p><code>sort -uk2</code> 基于第二列（<code>k2</code> 选项）进行排序，对于第二列相同的值只保留一次（<code>u</code> 选项）：</p><pre tabindex=0><code>1       abc
4       def
2       ghi
8       klm
5       xyz
</code></pre><p><code>sort -nk1</code> 基于第一列排序（<code>k1</code> 选项），把列的值作为数字来处理（<code>-n</code> 选项）：</p><pre tabindex=0><code>1       abc
2       ghi
4       def
5       xyz
8       klm
</code></pre><p>最后，<code>cut -f2-</code> 从第二列开始打印每一行，直到最后的内容（<code>-f2-</code> 选项：留意 <code>-</code> 后缀，它表示这行后面的内容都包含在内）。</p><pre tabindex=0><code>abc
ghi
def
xyz
klm
</code></pre><h3 id=参考>参考</h3><ul><li><a href=https://www.gnu.org/software/gawk/manual/html_node/>GNU awk 用户手册</a></li><li><a href=http://kirste.userpage.fu-berlin.de/chemnet/use/info/gawk/gawk_12.html>awk 中的数组</a></li><li><a href=https://www.gnu.org/software/gawk/manual/html_node/Truth-Values.html>Awk — 真值</a></li><li><a href=https://ftp.gnu.org/old-gnu/Manuals/gawk-3.0.3/html_chapter/gawk_8.html>Awk 表达式</a></li><li><a href=https://stackoverflow.com/questions/1444406/how-can-i-delete-duplicate-lines-in-a-file-in-unix>Unix 怎么删除文件中重复的行？</a></li><li><a href=https://stackoverflow.com/questions/11532157/remove-duplicate-lines-without-sorting>不用排序去掉重复的行（去重）</a></li><li><a href=https://unix.stackexchange.com/questions/159695/how-does-awk-a0-work/159734#159734>‘!a[$0]++’ 工作原理</a></li></ul><p>以上为全文。</p><hr><p>via: <a href=https://opensource.com/article/19/10/remove-duplicate-lines-files-awk>https://opensource.com/article/19/10/remove-duplicate-lines-files-awk</a></p><p>作者：<a href=https://opensource.com/users/iridakos>Lazarus Lazaridis</a> 选题：<a href=https://github.com/lujun9972>lujun9972</a> 译者：<a href=https://github.com/lxbwolf>lxbwolf</a> 校对：<a href=https://github.com/wxy>wxy</a></p><p>本文由 <a href=https://github.com/LCTT/TranslateProject>LCTT</a> 原创编译，<a href=https://linux.cn/>Linux中国</a> 荣誉推出</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/awk/ rel=tag>awk</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Linux.cn Archive.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>