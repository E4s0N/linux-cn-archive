<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Streams：一个新的 Redis 通用数据结构 - Linux.cn Archive</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="Streams：一个新的 Redis 通用数据结构"><meta property="og:description" content="直到几个月以前，对于我来说，在消息传递的环境中，流（streams）只是一个有趣且相对简单的概念。这个概念在 Kafka 流行之后，我主要研究它们在 Disque 案例中的应用，Disque 是一个消息队列，它将在 Redis 4.2 中被转换为 Redis 的一个模块。"><meta property="og:type" content="article"><meta property="og:url" content="/article-9879-1.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-07-29T21:47:00+00:00"><meta property="article:modified_time" content="2018-07-29T21:47:00+00:00"><meta itemprop=name content="Streams：一个新的 Redis 通用数据结构"><meta itemprop=description content="直到几个月以前，对于我来说，在消息传递的环境中，流（streams）只是一个有趣且相对简单的概念。这个概念在 Kafka 流行之后，我主要研究它们在 Disque 案例中的应用，Disque 是一个消息队列，它将在 Redis 4.2 中被转换为 Redis 的一个模块。"><meta itemprop=datePublished content="2018-07-29T21:47:00+00:00"><meta itemprop=dateModified content="2018-07-29T21:47:00+00:00"><meta itemprop=wordCount content="558"><meta itemprop=keywords content="Redis,数据结构,"><link rel=preconnect href=https://fonts.bunny.net crossorigin><link rel=dns-prefetch href=//fonts.bunny.net><link rel=dns-prefetch href=//fonts.bunny.net><link rel=stylesheet href="https://fonts.bunny.net/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Linux.cn Archive" rel=home><div class="logo__item logo__text"><div class=logo__title>Linux.cn Archive</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href=/categories/><span class=menu__text>Categories</span></a></li><li class=menu__item><a class=menu__link href=/tags/><span class=menu__text>Tags</span></a></li><li class=menu__item><a class=menu__link href><span class=menu__text>RSS</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Streams：一个新的 Redis 通用数据结构</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2018-07-29T21:47:00Z>July 29, 2018</time></div></div></header><div class="content post__content clearfix"><p><img src=/data/attachment/album/201807/29/214228bgcxede0etlljeb0.jpg alt></p><p>直到几个月以前，对于我来说，在消息传递的环境中， 流 streams 只是一个有趣且相对简单的概念。这个概念在 Kafka 流行之后，我主要研究它们在 Disque 案例中的应用，Disque 是一个消息队列，它将在 Redis 4.2 中被转换为 Redis 的一个模块。后来我决定让 Disque 都用 AP 消息（LCTT 译注：参见 <a href=https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86>CAP 定理</a>），也就是说，它将在不需要客户端过多参与的情况下实现容错和可用性，这样一来，我更加确定地认为流的概念在那种情况下并不适用。</p><p>然而在那时 Redis 有个问题，那就是缺省情况下导出数据结构并不轻松。它在 Redis 列表 list 、 有序集 sorted list 、 发布/订阅 Pub/Sub 功能之间有某些缺陷。你可以权衡使用这些工具对一系列消息或事件建模。</p><p>有序集是内存消耗大户，那自然就不能对投递的相同消息进行一次又一次的建模，客户端不能阻塞新消息。因为有序集并不是一个序列化的数据结构，它是一个元素可以根据它们量的变化而移动的集合：所以它不像时序性的数据那样。</p><p>列表有另外的问题，它在某些特定的用例中会产生类似的适用性问题：你无法浏览列表中间的内容，因为在那种情况下，访问时间是线性的。此外，没有任何指定输出的功能，列表上的阻塞操作仅为单个客户端提供单个元素。列表中没有固定的元素标识，也就是说，不能指定从哪个元素开始给我提供内容。</p><p>对于一对多的工作任务，有发布/订阅机制，它在大多数情况下是非常好的，但是，对于某些不想 “即发即弃” fire-and-forget 的东西：保留一个历史是很重要的，不只是因为是断开之后会重新获得消息，也因为某些如时序性的消息列表，用范围查询浏览是非常重要的：比如在这 10 秒范围内温度读数是多少？</p><p>我试图解决上述问题，我想规划一个通用的有序集合，并列入一个独特的、更灵活的数据结构，然而，我的设计尝试最终以生成一个比当前的数据结构更加矫揉造作的结果而告终。Redis 有个好处，它的数据结构导出更像自然的计算机科学的数据结构，而不是 “Salvatore 发明的 API”。因此，我最终停止了我的尝试，并且说，“ok，这是我们目前能提供的”，或许我会为发布/订阅增加一些历史信息，或者为列表访问增加一些更灵活的方式。然而，每次在会议上有用户对我说 “你如何在 Redis 中模拟时间系列” 或者类似的问题时，我的脸就绿了。</p><h3 id=起源>起源</h3><p>在 Redis 4.0 中引入模块之后，用户开始考虑他们自己怎么去修复这些问题。其中一个用户 Timothy Downs 通过 IRC 和我说道：</p><pre tabindex=0><code>\&lt;forkfork&gt; 我计划给这个模块增加一个事务日志式的数据类型 —— 这意味着大量的订阅者可以在不导致 redis 内存激增的情况下做一些像发布/订阅那样的事情
\&lt;forkfork&gt; 订阅者持有他们在消息队列中的位置，而不是让 Redis 必须维护每个消费者的位置和为每个订阅者复制消息
</code></pre><p>他的思路启发了我。我想了几天，并且意识到这可能是我们马上同时解决上面所有问题的契机。我需要去重新构思 “日志” 的概念是什么。日志是个基本的编程元素，每个人都使用过它，因为它只是简单地以追加模式打开一个文件，并以一定的格式写入数据。然而 Redis 数据结构必须是抽象的。它们在内存中，并且我们使用内存并不是因为我们懒，而是因为使用一些指针，我们可以概念化数据结构并把它们抽象，以使它们摆脱明确的限制。例如，一般来说日志有几个问题：偏移不是逻辑化的，而是真实的字节偏移，如果你想要与条目插入的时间相关的逻辑偏移应该怎么办？我们有范围查询可用。同样，日志通常很难进行垃圾回收：在一个只能进行追加操作的数据结构中怎么去删除旧的元素？好吧，在我们理想的日志中，我们只需要说，我想要数字最大的那个条目，而旧的元素一个也不要，等等。</p><p>当我从 Timothy 的想法中受到启发，去尝试着写一个规范的时候，我使用了 Redis 集群中的 radix 树去实现，优化了它内部的某些部分。这为实现一个有效利用空间的日志提供了基础，而且仍然有可能在 对数时间 logarithmic time 内访问范围。同时，我开始去读关于 Kafka 的流相关的内容以获得另外的灵感，它也非常适合我的设计，最后借鉴了 Kafka 消费组 consumer groups 的概念，并且再次针对 Redis 进行优化，以适用于 Redis 在内存中使用的情况。然而，该规范仅停留在纸面上，在一段时间后我几乎把它从头到尾重写了一遍，以便将我与别人讨论的所得到的许多建议一起增加到 Redis 升级中。我希望 Redis 流能成为对于时间序列有用的特性，而不仅是一个常见的事件和消息类的应用程序。</p><h3 id=让我们写一些代码吧>让我们写一些代码吧</h3><p>从 Redis 大会回来后，整个夏天我都在实现一个叫 listpack 的库。这个库是 <code>ziplist.c</code> 的继任者，那是一个表示在单个分配中的字符串元素列表的数据结构。它是一个非常特殊的序列化格式，其特点在于也能够以逆序（从右到左）解析：以便在各种用例中替代 ziplists。</p><p>结合 radix 树和 listpacks 的特性，它可以很容易地去构建一个空间高效的日志，并且还是可索引的，这意味着允许通过 ID 和时间进行随机访问。自从这些就绪后，我开始去写一些代码以实现流数据结构。我还在完成这个实现，不管怎样，现在在 Github 上的 Redis 的 streams 分支里它已经可以跑起来了。我并没有声称那个 API 是 100% 的最终版本，但是，这有两个有意思的事实：一，在那时只有消费群组是缺失的，加上一些不太重要的操作流的命令，但是，所有的大的方面都已经实现了。二，一旦各个方面比较稳定了之后，我决定大概用两个月的时间将所有的流的特性 向后移植 backport 到 4.0 分支。这意味着 Redis 用户想要使用流，不用等待 Redis 4.2 发布，它们在生产环境马上就可用了。这是可能的，因为作为一个新的数据结构，几乎所有的代码改变都出现在新的代码里面。除了阻塞列表操作之外：该代码被重构了，我们对于流和列表阻塞操作共享了相同的代码，而极大地简化了 Redis 内部实现。</p><h3 id=教程欢迎使用-redis-的-streams>教程：欢迎使用 Redis 的 streams</h3><p>在某些方面，你可以认为流是 Redis 列表的一个增强版本。流元素不再是一个单一的字符串，而是一个 字段 field 和 值 value 组成的对象。范围查询更适用而且更快。在流中，每个条目都有一个 ID，它是一个逻辑偏移量。不同的客户端可以 阻塞等待 blocking-wait 比指定的 ID 更大的元素。Redis 流的一个基本的命令是 <code>XADD</code>。是的，所有的 Redis 流命令都是以一个 <code>X</code> 为前缀的。</p><pre tabindex=0><code>&gt; XADD mystream * sensor-id 1234 temperature 10.5
1506871964177.0
</code></pre><p>这个 <code>XADD</code> 命令将追加指定的条目作为一个指定的流 —— “mystream” 的新元素。上面示例中的这个条目有两个字段：<code>sensor-id</code> 和 <code>temperature</code>，每个条目在同一个流中可以有不同的字段。使用相同的字段名可以更好地利用内存。有意思的是，字段的排序是可以保证顺序的。<code>XADD</code> 仅返回插入的条目的 ID，因为在第三个参数中是星号（<code>*</code>），表示由命令自动生成 ID。通常这样做就够了，但是也可以去强制指定一个 ID，这种情况用于复制这个命令到 从服务器 slave server 和 AOF append-only file 文件。</p><p>这个 ID 是由两部分组成的：一个毫秒时间和一个序列号。<code>1506871964177</code> 是毫秒时间，它只是一个毫秒级的 UNIX 时间戳。圆点（<code>.</code>）后面的数字 <code>0</code> 是一个序号，它是为了区分相同毫秒数的条目增加上去的。这两个数字都是 64 位的无符号整数。这意味着，我们可以在流中增加所有想要的条目，即使是在同一毫秒中。ID 的毫秒部分使用 Redis 服务器的当前本地时间生成的 ID 和流中的最后一个条目 ID 两者间的最大的一个。因此，举例来说，即使是计算机时间回跳，这个 ID 仍然是增加的。在某些情况下，你可以认为流条目的 ID 是完整的 128 位数字。然而，事实上它们与被添加到的实例的本地时间有关，这意味着我们可以在毫秒级的精度的范围随意查询。</p><p>正如你想的那样，快速添加两个条目后，结果是仅一个序号递增了。我们可以用一个 <code>MULTI</code>/<code>EXEC</code> 块来简单模拟“快速插入”：</p><pre tabindex=0><code>&gt; MULTI
OK
&gt; XADD mystream * foo 10
QUEUED
&gt; XADD mystream * bar 20
QUEUED
&gt; EXEC
1) 1506872463535.0
2) 1506872463535.1
</code></pre><p>在上面的示例中，也展示了无需指定任何初始 模式 schema 的情况下，对不同的条目使用不同的字段。会发生什么呢？就像前面提到的一样，只有每个块（它通常包含 50-150 个消息内容）的第一个消息被使用。并且，相同字段的连续条目都使用了一个标志进行了压缩，这个标志表示与“它们与这个块中的第一个条目的字段相同”。因此，使用相同字段的连续消息可以节省许多内存，即使是字段集随着时间发生缓慢变化的情况下也很节省内存。</p><p>为了从流中检索数据，这里有两种方法：范围查询，它是通过 <code>XRANGE</code> 命令实现的； 流播 streaming ，它是通过 <code>XREAD</code> 命令实现的。<code>XRANGE</code> 命令仅取得包括从开始到停止范围内的全部条目。因此，举例来说，如果我知道它的 ID，我可以使用如下的命名取得单个条目：</p><pre tabindex=0><code>&gt; XRANGE mystream 1506871964177.0 1506871964177.0
1) 1) 1506871964177.0
   2) 1) &#34;sensor-id&#34;
      2) &#34;1234&#34;
      3) &#34;temperature&#34;
      4) &#34;10.5&#34;
</code></pre><p>不管怎样，你都可以使用指定的开始符号 <code>-</code> 和停止符号 <code>+</code> 表示最小和最大的 ID。为了限制返回条目的数量，也可以使用 <code>COUNT</code> 选项。下面是一个更复杂的 <code>XRANGE</code> 示例：</p><pre tabindex=0><code>&gt; XRANGE mystream - + COUNT 2
1) 1) 1506871964177.0
   2) 1) &#34;sensor-id&#34;
      2) &#34;1234&#34;
      3) &#34;temperature&#34;
      4) &#34;10.5&#34;
2) 1) 1506872463535.0
   2) 1) &#34;foo&#34;
      2) &#34;10&#34;
</code></pre><p>这里我们讲的是 ID 的范围，然后，为了取得在一个给定时间范围内的特定范围的元素，你可以使用 <code>XRANGE</code>，因为 ID 的“序号” 部分可以省略。因此，你可以只指定“毫秒”时间即可，下面的命令的意思是：“从 UNIX 时间 1506872463 开始给我 10 个条目”：</p><pre tabindex=0><code>127.0.0.1:6379&gt; XRANGE mystream 1506872463000 + COUNT 10
1) 1) 1506872463535.0
   2) 1) &#34;foo&#34;
      2) &#34;10&#34;
2) 1) 1506872463535.1
   2) 1) &#34;bar&#34;
      2) &#34;20&#34;
</code></pre><p>关于 <code>XRANGE</code> 需要注意的最重要的事情是，假设我们在回复中收到 ID，随后连续的 ID 只是增加了序号部分，所以可以使用 <code>XRANGE</code> 遍历整个流，接收每个调用的指定个数的元素。Redis 中的<code>*SCAN</code> 系列命令允许迭代 Redis 数据结构，尽管事实上它们不是为迭代设计的，但这样可以避免再犯相同的错误。</p><h3 id=使用-xread-处理流播阻塞新的数据>使用 XREAD 处理流播：阻塞新的数据</h3><p>当我们想通过 ID 或时间去访问流中的一个范围或者是通过 ID 去获取单个元素时，使用 <code>XRANGE</code> 是非常完美的。然而，在使用流的案例中，当数据到达时，它必须由不同的客户端来消费时，这就不是一个很好的解决方案，这需要某种形式的 汇聚池 pooling 。（对于 <em>某些</em> 应用程序来说，这可能是个好主意，因为它们仅是偶尔连接查询的）</p><p><code>XREAD</code> 命令是为读取设计的，在同一个时间，从多个流中仅指定我们从该流中得到的最后条目的 ID。此外，如果没有数据可用，我们可以要求阻塞，当数据到达时，就解除阻塞。类似于阻塞列表操作产生的效果，但是这里并没有消费从流中得到的数据，并且多个客户端可以同时访问同一份数据。</p><p>这里有一个典型的 <code>XREAD</code> 调用示例：</p><pre tabindex=0><code>&gt; XREAD BLOCK 5000 STREAMS mystream otherstream $ $
</code></pre><p>它的意思是：从 <code>mystream</code> 和 <code>otherstream</code> 取得数据。如果没有数据可用，阻塞客户端 5000 毫秒。在 <code>STREAMS</code> 选项之后指定我们想要监听的关键字，最后的是指定想要监听的 ID，指定的 ID 为 <code>$</code> 的意思是：假设我现在需要流中的所有元素，因此，只需要从下一个到达的元素开始给我。</p><p>如果我从另一个客户端发送这样的命令：</p><pre tabindex=0><code>&gt; XADD otherstream * message “Hi There”
</code></pre><p>在 <code>XREAD</code> 侧会出现什么情况呢？</p><pre tabindex=0><code>1) 1) &#34;otherstream&#34;
   2) 1) 1) 1506935385635.0
         2) 1) &#34;message&#34;
            2) &#34;Hi There&#34;
</code></pre><p>与收到的数据一起，我们也得到了数据的关键字。在下次调用中，我们将使用接收到的最新消息的 ID：</p><pre tabindex=0><code>&gt; XREAD BLOCK 5000 STREAMS mystream otherstream $ 1506935385635.0
</code></pre><p>依次类推。然而需要注意的是使用方式，客户端有可能在一个非常大的延迟之后再次连接（因为它处理消息需要时间，或者其它什么原因）。在这种情况下，期间会有很多消息堆积，为了确保客户端不被消息淹没，以及服务器不会因为给单个客户端提供大量消息而浪费太多的时间，使用 <code>XREAD</code> 的 <code>COUNT</code> 选项是非常明智的。</p><h3 id=流封顶>流封顶</h3><p>目前看起来还不错……然而，有些时候，流需要删除一些旧的消息。幸运的是，这可以使用 <code>XADD</code> 命令的 <code>MAXLEN</code> 选项去做：</p><pre tabindex=0><code>&gt; XADD mystream MAXLEN 1000000 * field1 value1 field2 value2
</code></pre><p>它是基本意思是，如果在流中添加新元素后发现消息数量超过了 <code>1000000</code> 个，那么就删除旧的消息，以便于元素总量重新回到 <code>1000000</code> 以内。它很像是在列表中使用的 <code>RPUSH</code> + <code>LTRIM</code>，但是，这次我们是使用了一个内置机制去完成的。然而，需要注意的是，上面的意思是每次我们增加一个新的消息时，我们还需要另外的工作去从流中删除旧的消息。这将消耗一些 CPU 资源，所以在计算 <code>MAXLEN</code> 之前，尽可能使用 <code>~</code> 符号，以表明我们不要求非常 <em>精确</em> 的 1000000 个消息，就是稍微多一些也不是大问题：</p><pre tabindex=0><code>&gt; XADD mystream MAXLEN ~ 1000000 * foo bar
</code></pre><p>这种方式的 XADD 仅当它可以删除整个节点的时候才会删除消息。相比普通的 <code>XADD</code>，这种方式几乎可以自由地对流进行封顶。</p><h3 id=消费组开发中>消费组（开发中）</h3><p>这是第一个 Redis 中尚未实现而在开发中的特性。灵感也是来自 Kafka，尽管在这里是以不同的方式实现的。重点是使用了 <code>XREAD</code>，客户端也可以增加一个 <code>GROUP &lt;name></code> 选项。相同组的所有客户端将自动得到 <em>不同的</em> 消息。当然，同一个流可以被多个组读取。在这种情况下，所有的组将收到流中到达的消息的相同副本。但是，在每个组内，消息是不会重复的。</p><p>当指定组时，能够指定一个 <code>RETRY &lt;milliseconds></code> 选项去扩展组：在这种情况下，如果消息没有通过 <code>XACK</code> 进行确认，它将在指定的毫秒数后进行再次投递。这将为消息投递提供更佳的可靠性，这种情况下，客户端没有私有的方法将消息标记为已处理。这一部分也正在开发中。</p><h3 id=内存使用和节省加载时间>内存使用和节省加载时间</h3><p>因为用来建模 Redis 流的设计，内存使用率是非常低的。这取决于它们的字段、值的数量和长度，对于简单的消息，每使用 100MB 内存可以有几百万条消息。此外，该格式设想为需要极少的序列化：listpack 块以 radix 树节点方式存储，在磁盘上和内存中都以相同方式表示的，因此它们可以很轻松地存储和读取。例如，Redis 可以在 0.3 秒内从 RDB 文件中读取 500 万个条目。这使流的复制和持久存储非常高效。</p><p>我还计划允许从条目中间进行部分删除。现在仅实现了一部分，策略是在条目在标记中标识条目为已删除，并且，当已删除条目占全部条目的比例达到指定值时，这个块将被回收重写，如果需要，它将被连到相邻的另一个块上，以避免碎片化。</p><h3 id=关于最终发布时间的结论>关于最终发布时间的结论</h3><p>Redis 的流特性将包含在年底前（LCTT 译注：本文原文发布于 2017 年 10 月）推出的 Redis 4.0 系列的稳定版中。我认为这个通用的数据结构将为 Redis 提供一个巨大的补丁，以用于解决很多现在很难以解决的情况：那意味着你（之前）需要创造性地“滥用”当前提供的数据结构去解决那些问题。一个非常重要的使用场景是时间序列，但是，我觉得对于其它场景来说，通过 <code>TREAD</code> 来流播消息将是非常有趣的，因为对于那些需要更高可靠性的应用程序，可以使用发布/订阅模式来替换“即用即弃”，还有其它全新的使用场景。现在，如果你想在有问题环境中评估这个新数据结构，可以更新 GitHub 上的 streams 分支开始试用。欢迎向我们报告所有的 bug。:-)</p><p>如果你喜欢观看视频的方式，这里有一个现场演示：<a href="https://www.youtube.com/watch?v=ELDzy9lCFHQ">https://www.youtube.com/watch?v=ELDzy9lCFHQ</a></p><hr><p>via: <a href=http://antirez.com/news/114>http://antirez.com/news/114</a></p><p>作者：<a href=http://antirez.com/>antirez</a> 译者：<a href=https://github.com/qhwdw>qhwdw</a> 校对：<a href=https://github.com/wxy>wxy</a>, <a href=https://github.com/pityonline>pityonline</a></p><p>本文由 <a href=https://github.com/LCTT/TranslateProject>LCTT</a> 原创编译，<a href=https://linux.cn/>Linux中国</a> 荣誉推出</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/redis/ rel=tag>Redis</a></li><li class=tags__item><a class="tags__link btn" href=/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ rel=tag>数据结构</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Linux.cn Archive.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>