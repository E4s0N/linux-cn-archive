<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>大数据探索：在树莓派上通过 Apache Spark on YARN 搭建 Hadoop 集群 - Linux.cn Archive</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="大数据探索：在树莓派上通过 Apache Spark on YARN 搭建 Hadoop 集群"><meta property="og:description" content="今天我将向你展示对大数据的一点探索，不过有点变化，使用的是全世界最流行的微型电脑————树莓派"><meta property="og:type" content="article"><meta property="og:url" content="/article-8486-1.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-05-07T09:27:00+00:00"><meta property="article:modified_time" content="2017-05-07T09:27:00+00:00"><meta itemprop=name content="大数据探索：在树莓派上通过 Apache Spark on YARN 搭建 Hadoop 集群"><meta itemprop=description content="今天我将向你展示对大数据的一点探索，不过有点变化，使用的是全世界最流行的微型电脑————树莓派"><meta itemprop=datePublished content="2017-05-07T09:27:00+00:00"><meta itemprop=dateModified content="2017-05-07T09:27:00+00:00"><meta itemprop=wordCount content="786"><meta itemprop=keywords content="大数据,Hadoop,树莓派,"><link rel=preconnect href=https://fonts.bunny.net crossorigin><link rel=dns-prefetch href=//fonts.bunny.net><link rel=dns-prefetch href=//fonts.bunny.net><link rel=stylesheet href="https://fonts.bunny.net/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Linux.cn Archive" rel=home><div class="logo__item logo__text"><div class=logo__title>Linux.cn Archive</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href=/categories/><span class=menu__text>Categories</span></a></li><li class=menu__item><a class=menu__link href=/tags/><span class=menu__text>Tags</span></a></li><li class=menu__item><a class=menu__link href><span class=menu__text>RSS</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>大数据探索：在树莓派上通过 Apache Spark on YARN 搭建 Hadoop 集群</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2017-05-07T09:27:00Z>May 07, 2017</time></div></div></header><div class="content post__content clearfix"><p><img src=https://img.linux.net.cn/data/attachment/album/201705/07/023744ysdd41g0e4g45d1k.jpg alt></p><p>有些时候我们想从 DQYDJ 网站的数据中分析点有用的东西出来，在过去，我们要<a href=https://dqydj.com/how-to-import-fixed-width-data-into-a-spreadsheet-via-r-playing-with-ipums-cps-data/>用 R 语言提取固定宽度的数据</a>，然后通过数学建模来分析<a href=http://dqydj.com/negative-income-tax-cost-calculator-united-states/>美国的最低收入补贴</a>，当然也包括其他优秀的方法。</p><p>今天我将向你展示对大数据的一点探索，不过有点变化，使用的是全世界最流行的微型电脑————<a href=https://www.raspberrypi.org/>树莓派</a>，如果手头没有，那就看下一篇吧（可能是已经处理好的数据），对于其他用户，请继续阅读吧，今天我们要建立一个树莓派 Hadoop集群！</p><h3 id=i-为什么要建立一个树莓派的-hadoop-集群>I. 为什么要建立一个树莓派的 Hadoop 集群？</h3><p><img src=https://img.linux.net.cn/data/attachment/album/201705/07/023809pk52e4yff97f2ke4.png alt></p><p><em>由三个树莓派节点组成的 Hadoop 集群</em></p><p>我们对 DQYDJ 的数据做了<a href=https://dqydj.com/finance-calculators-investment-calculators-and-visualizations/>大量的处理工作</a>，但这些还不能称得上是大数据。</p><p>和许许多多有争议的话题一样，数据的大小之别被解释成这样一个笑话：</p><blockquote><p>如果能被内存所存储，那么它就不是大数据。 ————佚名</p></blockquote><p>似乎这儿有两种解决问题的方法：</p><ol><li>我们可以找到一个足够大的数据集合，任何家用电脑的物理或虚拟内存都存不下。</li><li>我们可以买一些不用特别定制，我们现有数据就能淹没它的电脑：<br>—— 上手树莓派 2B</li></ol><p>这个由设计师和工程师制作出来的精致小玩意儿拥有 1GB 的内存， MicroSD 卡充当它的硬盘，此外，每一台的价格都低于 50 美元，这意味着你可以花不到 250 美元的价格搭建一个 Hadoop 集群。</p><p>或许天下没有比这更便宜的入场券来带你进入大数据的大门。</p><h3 id=ii-制作一个树莓派集群>II. 制作一个树莓派集群</h3><p>我最喜欢制作的原材料。</p><p>这里我将给出我原来为了制作树莓派集群购买原材料的链接，如果以后要在亚马逊购买的话你可先这些链接收藏起来，也是对本站的一点支持。(谢谢)</p><ul><li><a href=http://amzn.to/2bEFTVh>树莓派 2B 3 块</a></li><li><a href=http://amzn.to/2bTo1br>4 层亚克力支架</a></li><li><a href=http://amzn.to/2bEGO8g>6 口 USB 转接器</a>，我选了白色 RAVPower 50W 10A 6 口 USB 转接器</li><li><a href=http://amzn.to/2cguV9I>MicroSD 卡</a>，这个五件套 32GB 卡非常棒</li><li><a href=http://amzn.to/2bX2mwm>短的 MicroUSB 数据线</a>，用于给树莓派供电</li><li><a href=http://amzn.to/2bDACQJ>短网线</a></li><li>双面胶，我有一些 3M 的，很好用</li></ul><h4 id=开始制作>开始制作</h4><ol><li>首先，装好三个树莓派，每一个用螺丝钉固定在亚克力面板上。（看下图）</li><li>接下来，安装以太网交换机，用双面胶贴在其中一个在亚克力面板上。</li><li>用双面胶贴将 USB 转接器贴在一个在亚克力面板使之成为最顶层。</li><li>接着就是一层一层都拼好——这里我选择将树莓派放在交换机和USB转接器的底下（可以看看完整安装好的两张截图）</li></ol><p>想办法把线路放在需要的地方——如果你和我一样购买力 USB 线和网线，我可以将它们卷起来放在亚克力板子的每一层</p><p>现在不要急着上电，需要将系统烧录到 SD 卡上才能继续。</p><h4 id=烧录-raspbian>烧录 Raspbian</h4><p>按照<a href=https://www.raspberrypi.org/downloads/raspbian/>这个教程</a>将 Raspbian 烧录到三张 SD 卡上，我使用的是 Win7 下的 <a href=https://sourceforge.net/projects/win32diskimager/>Win32DiskImager</a>。</p><p>将其中一张烧录好的 SD 卡插在你想作为主节点的树莓派上，连接 USB 线并启动它。</p><h4 id=启动主节点>启动主节点</h4><p>这里有<a href=http://www.becausewecangeek.com/building-a-raspberry-pi-hadoop-cluster-part-1/>一篇非常棒的“Because We Can Geek”的教程</a>，讲如何安装 Hadoop 2.7.1，此处就不再熬述。</p><p>在启动过程中有一些要注意的地方，我将带着你一起设置直到最后一步，记住我现在使用的 IP 段为 192.168.1.50 – 192.168.1.52，主节点是 .50，从节点是 .51 和 .52，你的网络可能会有所不同，如果你想设置静态 IP 的话可以在评论区看看或讨论。</p><p>一旦你完成了这些步骤，接下来要做的就是启用交换文件，Spark on YARN 将分割出一块非常接近内存大小的交换文件，当你内存快用完时便会使用这个交换分区。</p><p>（如果你以前没有做过有关交换分区的操作的话，可以看看<a href=https://www.digitalocean.com/community/tutorials/how-to-add-swap-on-ubuntu-14-04>这篇教程</a>，让 <code>swappiness</code> 保持较低水准，因为 MicroSD 卡的性能扛不住）</p><p>现在我准备介绍有关我的和“Because We Can Geek”关于启动设置一些微妙的区别。</p><p>对于初学者，确保你给你的树莓派起了一个正式的名字——在 <code>/etc/hostname</code> 设置，我的主节点设置为 ‘RaspberryPiHadoopMaster’ ，从节点设置为 ‘RaspberryPiHadoopSlave#’</p><p>主节点的 <code>/etc/hosts</code> 配置如下：</p><pre tabindex=0><code>#/etc/hosts
127.0.0.1       localhost
::1             localhost ip6-localhost ip6-loopback
ff02::1         ip6-allnodes
ff02::2         ip6-allrouters

192.168.1.50    RaspberryPiHadoopMaster
192.168.1.51    RaspberryPiHadoopSlave1
192.168.1.52    RaspberryPiHadoopSlave2
</code></pre><p>如果你想让 Hadoop、YARN 和 Spark 运行正常的话，你也需要修改这些配置文件（不妨现在就编辑）。</p><p>这是 <code>hdfs-site.xml</code>：</p><pre tabindex=0><code>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;
&lt;configuration&gt;
&lt;property&gt;  
  &lt;name&gt;fs.default.name&lt;/name&gt;
  &lt;value&gt;hdfs://RaspberryPiHadoopMaster:54310&lt;/value&gt;
&lt;/property&gt;  
&lt;property&gt;  
  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
  &lt;value&gt;/hdfs/tmp&lt;/value&gt;
&lt;/property&gt;  
&lt;/configuration&gt;
</code></pre><p>这是 <code>yarn-site.xml</code> （注意内存方面的改变）：</p><pre tabindex=0><code>&lt;?xml version=&#34;1.0&#34;?&gt;
&lt;configuration&gt;

&lt;!-- Site specific YARN configuration properties --&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
    &lt;value&gt;4&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
    &lt;value&gt;1024&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
    &lt;value&gt;128&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
    &lt;value&gt;1024&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.minimum-allocation-vcores&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.maximum-allocation-vcores&lt;/name&gt;
    &lt;value&gt;4&lt;/value&gt;
  &lt;/property&gt;
&lt;property&gt;
   &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
   &lt;value&gt;false&lt;/value&gt;
   &lt;description&gt;Whether virtual memory limits will be enforced for containers&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
   &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;
   &lt;value&gt;4&lt;/value&gt;
   &lt;description&gt;Ratio between virtual memory to physical memory when setting memory limits for containers&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;  
&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;  
&lt;value&gt;RaspberryPiHadoopMaster:8025&lt;/value&gt;  
&lt;/property&gt;  
&lt;property&gt;  
&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;  
&lt;value&gt;RaspberryPiHadoopMaster:8030&lt;/value&gt;  
&lt;/property&gt;  
&lt;property&gt;  
&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;  
&lt;value&gt;RaspberryPiHadoopMaster:8040&lt;/value&gt;  
&lt;/property&gt; 
&lt;/configuration&gt;
</code></pre><p><code>slaves</code>：</p><pre tabindex=0><code>RaspberryPiHadoopMaster
RaspberryPiHadoopSlave1
RaspberryPiHadoopSlave2
</code></pre><p><code>core-site.xml</code>：</p><pre tabindex=0><code>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;
&lt;configuration&gt;
&lt;property&gt;  
  &lt;name&gt;fs.default.name&lt;/name&gt;
  &lt;value&gt;hdfs://RaspberryPiHadoopMaster:54310&lt;/value&gt;
&lt;/property&gt;  
&lt;property&gt;  
  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
  &lt;value&gt;/hdfs/tmp&lt;/value&gt;
&lt;/property&gt;  
&lt;/configuration&gt;
</code></pre><h4 id=设置两个从节点>设置两个从节点：</h4><p>接下来<a href=http://www.becausewecangeek.com/building-a-raspberry-pi-hadoop-cluster-part-2/>按照 “Because We Can Geek”上的教程</a>，你需要对上面的文件作出小小的改动。 在 <code>yarn-site.xml</code> 中主节点没有改变，所以从节点中不必含有这个 <code>slaves</code> 文件。</p><h3 id=iii-在我们的树莓派集群中测试-yarn>III. 在我们的树莓派集群中测试 YARN</h3><p>如果所有设备都正常工作，在主节点上你应该执行如下命令：</p><pre tabindex=0><code>start-dfs.sh
start-yarn.sh
</code></pre><p>当设备启动后，以 Hadoop 用户执行，如果你遵循教程，用户应该是 <code>hduser</code>。</p><p>接下来执行 <code>hdfs dfsadmin -report</code> 查看三个节点是否都正确启动，确认你看到一行粗体文字 ‘Live datanodes (3)’：</p><pre tabindex=0><code>Configured Capacity: 93855559680 (87.41 GB)
Raspberry Pi Hadoop Cluster picture Straight On
Present Capacity: 65321992192 (60.84 GB)
DFS Remaining: 62206627840 (57.93 GB)
DFS Used: 3115364352 (2.90 GB)
DFS Used%: 4.77%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0
Missing blocks (with replication factor 1): 0
————————————————-
Live datanodes (3):
Name: 192.168.1.51:50010 (RaspberryPiHadoopSlave1)
Hostname: RaspberryPiHadoopSlave1
Decommission Status : Normal
</code></pre><p>你现在可以做一些简单的诸如 ‘Hello, World!’ 的测试，或者直接进行下一步。</p><h3 id=iv-安装-spark-on-yarn>IV. 安装 SPARK ON YARN</h3><p>YARN 的意思是另一种非常好用的资源调度器（Yet Another Resource Negotiator），已经作为一个易用的资源管理器集成在 Hadoop 基础安装包中。</p><p><a href=https://spark.apache.org/>Apache Spark</a> 是 Hadoop 生态圈中的另一款软件包，它是一个毁誉参半的执行引擎和<a href=https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html>捆绑的 MapReduce</a>。在一般情况下，相对于基于磁盘存储的 MapReduce，Spark 更适合基于内存的存储，某些运行任务能够得到 10-100 倍提升——安装完成集群后你可以试试 Spark 和 MapReduce 有什么不同。</p><p>我个人对 Spark 还是留下非常深刻的印象，因为它提供了两种数据工程师和科学家都比较擅长的语言—— Python 和 R。</p><p>安装 Apache Spark 非常简单，在你家目录下，<code>wget "为 Hadoop 2.7 构建的 Apache Spark”</code>（<a href=https://spark.apache.org/downloads.html>来自这个页面</a>），然后运行 <code>tar -xzf “tgz 文件”</code>，最后把解压出来的文件移动至 <code>/opt</code>，并清除刚才下载的文件，以上这些就是安装步骤。</p><p>我又创建了只有两行的文件 <code>spark-env.sh</code>，其中包含 Spark 的配置文件目录。</p><pre tabindex=0><code>SPARK_MASTER_IP=192.168.1.50
SPARK_WORKER_MEMORY=512m
</code></pre><p>(在 YARN 跑起来之前我不确定这些是否有必要。)</p><h3 id=v-你好世界-为-apache-spark-寻找有趣的数据集>V. 你好，世界! 为 Apache Spark 寻找有趣的数据集!</h3><p>在 Hadoop 世界里面的 ‘Hello, World!’ 就是做单词计数。</p><p>我决定让我们的作品做一些内省式……为什么不统计本站最常用的单词呢？也许统计一些关于本站的大数据会更有用。</p><p>如果你有一个正在运行的 WordPress 博客，可以通过简单的两步来导出和净化。</p><ol><li>我使用 <a href=https://wordpress.org/support/plugin/export-to-text>Export to Text</a> 插件导出文章的内容到纯文本文件中</li><li>我使用一些<a href=https://pypi.python.org/pypi/bleach>压缩库</a>编写了一个 Python 脚本来剔除 HTML</li></ol><pre tabindex=0><code>import bleach

# Change this next line to your &#39;import&#39; filename, whatever you would like to strip
# HTML tags from.
ascii_string = open(&#39;dqydj_with_tags.txt&#39;, &#39;r&#39;).read()


new_string = bleach.clean(ascii_string, tags=[], attributes={}, styles=[], strip=True)
new_string = new_string.encode(&#39;utf-8&#39;).strip()

# Change this next line to your &#39;export&#39; filename
f = open(&#39;dqydj_stripped.txt&#39;, &#39;w&#39;)
f.write(new_string)
f.close()
</code></pre><p>现在我们有了一个更小的、适合复制到树莓派所搭建的 HDFS 集群上的文件。</p><p>如果你不能树莓派主节点上完成上面的操作，找个办法将它传输上去（scp、 rsync 等等），然后用下列命令行复制到 HDFS 上。</p><pre tabindex=0><code>hdfs dfs -copyFromLocal dqydj_stripped.txt /dqydj_stripped.txt
</code></pre><p>现在准备进行最后一步 - 向 Apache Spark 写入一些代码。</p><h3 id=vi-点亮-apache-spark>VI. 点亮 Apache Spark</h3><p>Cloudera 有个极棒的程序可以作为我们的超级单词计数程序的基础，<a href=https://www.cloudera.com/documentation/enterprise/5-6-x/topics/spark_develop_run.html>你可以在这里找到</a>。我们接下来为我们的内省式单词计数程序修改它。</p><p>在主节点上<a href=https://pypi.python.org/pypi/stop-words>安装‘stop-words’</a>这个 python 第三方包，虽然有趣（我在 DQYDJ 上使用了 23,295 次 the 这个单词），你可能不想看到这些语法单词占据着单词计数的前列，另外，在下列代码用你自己的数据集替换所有有关指向 dqydj 文件的地方。</p><pre tabindex=0><code>import sys

from stop_words import get_stop_words
from pyspark import SparkContext, SparkConf

if __name__ == &#34;__main__&#34;:

  # create Spark context with Spark configuration
  conf = SparkConf().setAppName(&#34;Spark Count&#34;)
  sc = SparkContext(conf=conf)

  # get threshold
  try:
    threshold = int(sys.argv[2])
  except:
    threshold = 5

  # read in text file and split each document into words
  tokenized = sc.textFile(sys.argv[1]).flatMap(lambda line: line.split(&#34; &#34;))

  # count the occurrence of each word
  wordCounts = tokenized.map(lambda word: (word.lower().strip(), 1)).reduceByKey(lambda v1,v2:v1 +v2)

  # filter out words with fewer than threshold occurrences
  filtered = wordCounts.filter(lambda pair:pair[1] &gt;= threshold)

  print &#34;*&#34; * 80
  print &#34;Printing top words used&#34;
  print &#34;-&#34; * 80
  filtered_sorted = sorted(filtered.collect(), key=lambda x: x[1], reverse = True)
  for (word, count) in filtered_sorted: print &#34;%s : %d&#34; % (word.encode(&#39;utf-8&#39;).strip(), count)


  # Remove stop words
  print &#34;\n\n&#34;
  print &#34;*&#34; * 80
  print &#34;Printing top non-stop words used&#34;
  print &#34;-&#34; * 80
  # Change this to your language code (see the stop-words documentation)
  stop_words = set(get_stop_words(&#39;en&#39;))
  no_stop_words = filter(lambda x: x[0] not in stop_words, filtered_sorted)
  for (word, count) in no_stop_words: print &#34;%s : %d&#34; % (word.encode(&#39;utf-8&#39;).strip(), count)
</code></pre><p>保存好 wordCount.py，确保上面的路径都是正确无误的。</p><p>现在，准备念出咒语，让运行在 YARN 上的 Spark 跑起来，你可以看到我在 DQYDJ 使用最多的单词是哪一个。</p><pre tabindex=0><code>/opt/spark-2.0.0-bin-hadoop2.7/bin/spark-submit –master yarn –executor-memory 512m –name wordcount –executor-cores 8 wordCount.py /dqydj_stripped.txt
</code></pre><h3 id=vii-我在-dqydj-使用最多的单词>VII. 我在 DQYDJ 使用最多的单词</h3><p>可能入列的单词有哪一些呢？“can, will, it’s, one, even, like, people, money, don’t, also“.</p><p>嘿，不错，“money”悄悄挤进了前十。在一个致力于金融、投资和经济的网站上谈论这似乎是件好事，对吧？</p><p>下面是的前 50 个最常用的词汇，请用它们刻画出有关我的文章的水平的结论。</p><p><img src=https://img.linux.net.cn/data/attachment/album/201705/07/023810wrwuwarhr6z6hpph.png alt></p><p>我希望你能喜欢这篇关于 Hadoop、YARN 和 Apache Spark 的教程，现在你可以在 Spark 运行和编写其他的应用了。</p><p>你的下一步是任务是开始<a href=https://spark.apache.org/docs/2.0.0/api/python/index.html>阅读 pyspark 文档</a>（以及用于其他语言的该库），去学习一些可用的功能。根据你的兴趣和你实际存储的数据，你将会深入学习到更多——有流数据、SQL，甚至机器学习的软件包！</p><p>你怎么看？你要建立一个树莓派 Hadoop 集群吗？想要在其中挖掘一些什么吗？你在上面看到最令你惊奇的单词是什么？为什么 &lsquo;S&amp;P&rsquo; 也能上榜？</p><p>（题图：Pixabay，CC0）</p><hr><p>via: <a href=https://dqydj.com/raspberry-pi-hadoop-cluster-apache-spark-yarn/>https://dqydj.com/raspberry-pi-hadoop-cluster-apache-spark-yarn/</a></p><p>作者：<a href=https://dqydj.com/about/#contact_us>PK</a> 译者：<a href=https://github.com/sfantree>popy32</a> 校对：<a href=https://github.com/wxy>wxy</a></p><p>本文由 <a href=https://github.com/LCTT/TranslateProject>LCTT</a> 组织编译，<a href=https://linux.cn/>Linux中国</a> 荣誉推出</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/ rel=tag>大数据</a></li><li class=tags__item><a class="tags__link btn" href=/tags/hadoop/ rel=tag>Hadoop</a></li><li class=tags__item><a class="tags__link btn" href=/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/ rel=tag>树莓派</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Linux.cn Archive.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>