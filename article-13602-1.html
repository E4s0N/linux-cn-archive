<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>进阶教程：用 Python 和 NLTK 进行 NLP 分析 - Linux.cn Archive</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="进阶教程：用 Python 和 NLTK 进行 NLP 分析"><meta property="og:description" content="进一步学习自然语言处理的基本概念"><meta property="og:type" content="article"><meta property="og:url" content="/article-13602-1.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-07-21T11:56:00+00:00"><meta property="article:modified_time" content="2021-07-21T11:56:00+00:00"><meta itemprop=name content="进阶教程：用 Python 和 NLTK 进行 NLP 分析"><meta itemprop=description content="进一步学习自然语言处理的基本概念"><meta itemprop=datePublished content="2021-07-21T11:56:00+00:00"><meta itemprop=dateModified content="2021-07-21T11:56:00+00:00"><meta itemprop=wordCount content="1251"><meta itemprop=keywords content="NLP,自然语言处理,"><link rel=preconnect href=https://fonts.bunny.net crossorigin><link rel=dns-prefetch href=//fonts.bunny.net><link rel=dns-prefetch href=//fonts.bunny.net><link rel=stylesheet href="https://fonts.bunny.net/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Linux.cn Archive" rel=home><div class="logo__item logo__text"><div class=logo__title>Linux.cn Archive</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href=/categories/><span class=menu__text>Categories</span></a></li><li class=menu__item><a class=menu__link href=/tags/><span class=menu__text>Tags</span></a></li><li class=menu__item><a class=menu__link href><span class=menu__text>RSS</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>进阶教程：用 Python 和 NLTK 进行 NLP 分析</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-07-21T11:56:00Z>July 21, 2021</time></div></div></header><div class="content post__content clearfix"><blockquote><p>进一步学习自然语言处理的基本概念</p></blockquote><p><img src=https://img.linux.net.cn/data/attachment/album/202107/21/115633k8l9nkqowqkowpwm.jpg alt title="Brain on a computer screen"></p><p>在 <a href=https://opensource.com/article/20/8/intro-python-nltk>之前的文章</a> 里，我介绍了 自然语言处理 natural language processing （NLP）和宾夕法尼亚大学研发的 自然语言处理工具包 Natural Language Toolkit (<a href=http://www.nltk.org/>NLTK</a>)。我演示了用 Python 解析文本和定义 停顿词 stopword 的方法，并介绍了 语料库 corpus 的概念。语料库是由文本构成的数据集，通过提供现成的文本数据来辅助文本处理。在这篇文章里，我将继续用各种语料库对文本进行对比和分析。</p><p>这篇文章主要包括以下部分：</p><ul><li>词网 WordNet 和 同义词集 synset</li><li>相似度比较 Similarity comparison</li><li>树 Tree 和 树库 treebank</li><li>命名实体识别 Named entity recognition</li></ul><h3 id=词网和同义词集>词网和同义词集</h3><p>词网 WordNet 是 NLTK 里的一个大型词汇数据库语料库。词网包含各单词的诸多 认知同义词 cognitive synonyms （认知同义词常被称作“ 同义词集 synset ”）。在词网里，名词、动词、形容词和副词，各自被组织成一个同义词的网络。</p><p>词网是一个很有用的文本分析工具。它有面向多种语言的版本（汉语、英语、日语、俄语和西班牙语等），也使用多种许可证（从开源许可证到商业许可证都有）。初代版本的词网由普林斯顿大学研发，面向英语，使用 类 MIT 许可证 MIT-like license 。</p><p>因为一个词可能有多个意义或多个词性，所以可能与多个同义词集相关联。每个同义词集通常提供下列属性：</p><table><thead><tr><th><strong>属性</strong></th><th><strong>定义</strong></th><th><strong>例子</strong></th></tr></thead><tbody><tr><td>名称 Name</td><td>此同义词集的名称</td><td>单词 <code>code</code> 有 5 个同义词集，名称分别是 <code>code.n.01</code>、 <code>code.n.02</code>、 <code>code.n.03</code>、<code>code.v.01</code> 和 <code>code.v.02</code></td></tr><tr><td>词性 POS</td><td>此同义词集的词性</td><td>单词 <code>code</code> 有 3 个名词词性的同义词集和 2 个动词词性的同义词集</td></tr><tr><td>定义 Definition</td><td>该词作对应词性时的定义</td><td>动词 <code>code</code> 的一个定义是：（计算机科学）数据或计算机程序指令的 象征性排列 symbolic arrangement</td></tr><tr><td>例子 Example</td><td>使用该词的例子</td><td><code>code</code> 一词的例子：We should encode the message for security reasons</td></tr><tr><td>词元 Lemma</td><td>与该词相关联的其他同义词集（包括那些不一定严格地是该词的同义词，但可以大体看作同义词的）；词元直接与其他词元相关联，而不是直接与 单词 word 相关联</td><td><code>code.v.02</code> 的词元是 <code>code.v.02.encipher</code>、<code>code.v.02.cipher</code>、<code>code.v.02.cypher</code>、<code>code.v.02.encrypt</code>、<code>code.v.02.inscribe</code> 和 <code>code.v.02.write_in_code</code></td></tr><tr><td>反义词 Antonym</td><td>意思相反的词</td><td>词元 <code>encode.v.01.encode</code> 的反义词是 <code>decode.v.01.decode</code></td></tr><tr><td>上义词 Hypernym</td><td>该词所属的一个范畴更大的词</td><td><code>code.v.01</code> 的一个上义词是 <code>tag.v.01</code></td></tr><tr><td>分项词 Meronym</td><td>属于该词组成部分的词</td><td><code>computer</code> 的一个分项词是 <code>chip</code></td></tr><tr><td>总项词 Holonym</td><td>该词作为组成部分所属的词</td><td><code>window</code> 的一个总项词是 <code>computer screen</code></td></tr></tbody></table><p>同义词集还有一些其他属性，在 <code>&lt;你的 Python 安装路径>/Lib/site-packages</code> 下的 <code>nltk/corpus/reader/wordnet.py</code>，你可以找到它们。</p><p>下面的代码或许可以帮助理解。</p><p>这个函数：</p><pre tabindex=0><code>from nltk.corpus import wordnet

def synset_info(synset):
    print(&#34;Name&#34;, synset.name())
    print(&#34;POS:&#34;, synset.pos())
    print(&#34;Definition:&#34;, synset.definition())
    print(&#34;Examples:&#34;, synset.examples())
    print(&#34;Lemmas:&#34;, synset.lemmas())
    print(&#34;Antonyms:&#34;, [lemma.antonyms() for lemma in synset.lemmas() if len(lemma.antonyms()) &gt; 0])
    print(&#34;Hypernyms:&#34;, synset.hypernyms())
    print(&#34;Instance Hypernyms:&#34;, synset.instance_hypernyms())
    print(&#34;Part Holonyms:&#34;, synset.part_holonyms())
    print(&#34;Part Meronyms:&#34;, synset.part_meronyms())
    print()


synsets = wordnet.synsets(&#39;code&#39;)
print(len(synsets), &#34;synsets:&#34;)
for synset in synsets:
    synset_info(synset)
</code></pre><p>将会显示：</p><pre tabindex=0><code>5 synsets:
Name code.n.01
POS: n
Definition: a set of rules or principles or laws (especially written ones)
Examples: []
Lemmas: [Lemma(&#39;code.n.01.code&#39;), Lemma(&#39;code.n.01.codification&#39;)]
Antonyms: []
Hypernyms: [Synset(&#39;written_communication.n.01&#39;)]
Instance Hpernyms: []
Part Holonyms: []
Part Meronyms: []

...

Name code.n.03
POS: n
Definition: (computer science) the symbolic arrangement of data or instructions in a computer program or the set of such instructions
Examples: []
Lemmas: [Lemma(&#39;code.n.03.code&#39;), Lemma(&#39;code.n.03.computer_code&#39;)]
Antonyms: []
Hypernyms: [Synset(&#39;coding_system.n.01&#39;)]
Instance Hpernyms: []
Part Holonyms: []
Part Meronyms: []

...

Name code.v.02
POS: v
Definition: convert ordinary language into code
Examples: [&#39;We should encode the message for security reasons&#39;]
Lemmas: [Lemma(&#39;code.v.02.code&#39;), Lemma(&#39;code.v.02.encipher&#39;), Lemma(&#39;code.v.02.cipher&#39;), Lemma(&#39;code.v.02.cypher&#39;), Lemma(&#39;code.v.02.encrypt&#39;), Lemma(&#39;code.v.02.inscribe&#39;), Lemma(&#39;code.v.02.write_in_code&#39;)]
Antonyms: []
Hypernyms: [Synset(&#39;encode.v.01&#39;)]
Instance Hpernyms: []
Part Holonyms: []
Part Meronyms: []
</code></pre><p>同义词集 synset 和 词元 lemma 在词网里是按照树状结构组织起来的，下面的代码会给出直观的展现：</p><pre tabindex=0><code>def hypernyms(synset):
    return synset.hypernyms()

synsets = wordnet.synsets(&#39;soccer&#39;)
for synset in synsets:
    print(synset.name() + &#34; tree:&#34;)
    pprint(synset.tree(rel=hypernyms))
    print()
</code></pre><pre tabindex=0><code>code.n.01 tree:
[Synset(&#39;code.n.01&#39;),
 [Synset(&#39;written_communication.n.01&#39;),
   ...

code.n.02 tree:
[Synset(&#39;code.n.02&#39;),
 [Synset(&#39;coding_system.n.01&#39;),
   ...

code.n.03 tree:
[Synset(&#39;code.n.03&#39;),
   ...

code.v.01 tree:
[Synset(&#39;code.v.01&#39;),
 [Synset(&#39;tag.v.01&#39;),
   ...

code.v.02 tree:
[Synset(&#39;code.v.02&#39;),
 [Synset(&#39;encode.v.01&#39;),
   ...
</code></pre><p>词网并没有涵盖所有的单词和其信息（现今英语有约 17,0000 个单词，最新版的 词网 涵盖了约 15,5000 个），但它开了个好头。掌握了“词网”的各个概念后，如果你觉得它词汇少，不能满足你的需要，可以转而使用其他工具。或者，你也可以打造自己的“词网”！</p><h4 id=自主尝试>自主尝试</h4><p>使用 Python 库，下载维基百科的 “<a href=https://en.wikipedia.org/wiki/Open_source>open source</a>” 页面，并列出该页面所有单词的 同义词集 synset 和 词元 lemma 。</p><h3 id=相似度比较>相似度比较</h3><p>相似度比较的目的是识别出两篇文本的相似度，在搜索引擎、聊天机器人等方面有很多应用。</p><p>比如，相似度比较可以识别 <code>football</code> 和 <code>soccer</code> 是否有相似性。</p><pre tabindex=0><code>syn1 = wordnet.synsets(&#39;football&#39;)
syn2 = wordnet.synsets(&#39;soccer&#39;)

# 一个单词可能有多个 同义词集，需要把 word1 的每个同义词集和 word2 的每个同义词集分别比较
for s1 in syn1:
    for s2 in syn2:
        print(&#34;Path similarity of: &#34;)
        print(s1, &#39;(&#39;, s1.pos(), &#39;)&#39;, &#39;[&#39;, s1.definition(), &#39;]&#39;)
        print(s2, &#39;(&#39;, s2.pos(), &#39;)&#39;, &#39;[&#39;, s2.definition(), &#39;]&#39;)
        print(&#34;   is&#34;, s1.path_similarity(s2))
        print()
</code></pre><pre tabindex=0><code>Path similarity of:
Synset(&#39;football.n.01&#39;) ( n ) [ any of various games played with a ball (round or oval) in which two teams try to kick or carry or propel the ball into each other&#39;s goal ]
Synset(&#39;soccer.n.01&#39;) ( n ) [ a football game in which two teams of 11 players try to kick or head a ball into the opponents&#39; goal ]
   is 0.5

Path similarity of:
Synset(&#39;football.n.02&#39;) ( n ) [ the inflated oblong ball used in playing American football ]
Synset(&#39;soccer.n.01&#39;) ( n ) [ a football game in which two teams of 11 players try to kick or head a ball into the opponents&#39; goal ]
   is 0.05
</code></pre><p>两个词各个同义词集之间 路径相似度 path similarity 最大的是 0.5，表明它们关联性很大（<a href=https://www.nltk.org/howto/wordnet.html> 路径相似度 path similarity </a>指两个词的意义在 上下义关系的词汇分类结构 hypernym/hypnoym taxonomy 中的最短距离）。</p><p>那么 <code>code</code> 和 <code>bug</code> 呢？这两个计算机领域的词的相似度是：</p><pre tabindex=0><code>Path similarity of:
Synset(&#39;code.n.01&#39;) ( n ) [ a set of rules or principles or laws (especially written ones) ]
Synset(&#39;bug.n.02&#39;) ( n ) [ a fault or defect in a computer program, system, or machine ]
   is 0.1111111111111111
...
Path similarity of:
Synset(&#39;code.n.02&#39;) ( n ) [ a coding system used for transmitting messages requiring brevity or secrecy ]
Synset(&#39;bug.n.02&#39;) ( n ) [ a fault or defect in a computer program, system, or machine ]
   is 0.09090909090909091
...
Path similarity of:
Synset(&#39;code.n.03&#39;) ( n ) [ (computer science) the symbolic arrangement of data or instructions in a computer program or the set of such instructions ]
Synset(&#39;bug.n.02&#39;) ( n ) [ a fault or defect in a computer program, system, or machine ]
   is 0.09090909090909091
</code></pre><p>这些是这两个词各同义词集之间 路径相似度 path similarity 的最大值，这些值表明两个词是有关联性的。</p><p>NLTK 提供多种 相似度计分器 similarity scorers ，比如：</p><ul><li>path_similarity</li><li>lch_similarity</li><li>wup_similarity</li><li>res_similarity</li><li>jcn_similarity</li><li>lin_similarity</li></ul><p>要进一步了解这些 相似度计分器 similarity scorers ，请查看 <a href=https://www.nltk.org/howto/wordnet.html>WordNet Interface</a> 的 Similarity 部分。</p><h4 id=自主尝试-1>自主尝试</h4><p>使用 Python 库，从维基百科的 <a href=https://en.wikipedia.org/wiki/Category:Lists_of_computer_terms>Category: Lists of computer terms</a> 生成一个术语列表，然后计算各术语之间的相似度。</p><h3 id=树和树库>树和树库</h3><p>使用 NLTK，你可以把文本表示成树状结构以便进行分析。</p><p>这里有一个例子：</p><p>这是一份简短的文本，对其做预处理和词性标注：</p><pre tabindex=0><code>import nltk

text = &#34;I love open source&#34;
# Tokenize to words
words = nltk.tokenize.word_tokenize(text)
# POS tag the words
words_tagged = nltk.pos_tag(words)
</code></pre><p>要把文本转换成树状结构，你必须定义一个 语法 grammar 。这个例子里用的是一个基于 <a href=https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html>Penn Treebank tags</a> 的简单语法。</p><pre tabindex=0><code># A simple grammar to create tree
grammar = &#34;NP: {&amp;lt;JJ&amp;gt;&amp;lt;NN&amp;gt;}&#34;
</code></pre><p>然后用这个 语法 grammar 创建一颗 树 tree ：</p><pre tabindex=0><code># Create tree
parser = nltk.RegexpParser(grammar)
tree = parser.parse(words_tagged)
pprint(tree)
</code></pre><p>运行上面的代码，将得到：</p><pre tabindex=0><code>Tree(&#39;S&#39;, [(&#39;I&#39;, &#39;PRP&#39;), (&#39;love&#39;, &#39;VBP&#39;), Tree(&#39;NP&#39;, [(&#39;open&#39;, &#39;JJ&#39;), (&#39;source&#39;, &#39;NN&#39;)])])
</code></pre><p>你也可以图形化地显示结果。</p><pre tabindex=0><code>tree.draw()
</code></pre><p><img src=https://img.linux.net.cn/data/attachment/album/202107/21/115644oswzxowwad5ldxww.jpg alt="NLTK Tree" title="NLTK Tree"></p><p>这个树状结构有助于准确解读文本的意思。比如，用它可以找到文本的 <a href=https://en.wikipedia.org/wiki/Subject_(grammar)>主语</a>：</p><pre tabindex=0><code>subject_tags = [&#34;NN&#34;, &#34;NNS&#34;, &#34;NP&#34;, &#34;NNP&#34;, &#34;NNPS&#34;, &#34;PRP&#34;, &#34;PRP$&#34;]
def subject(sentence_tree):
    for tagged_word in sentence_tree:
        # A crude logic for this case -  first word with these tags is considered subject
        if tagged_word[1] in subject_tags:
            return tagged_word[0]

print(&#34;Subject:&#34;, subject(tree))
</code></pre><p>结果显示主语是 <code>I</code>：</p><pre tabindex=0><code>Subject: I
</code></pre><p>这是一个比较基础的文本分析步骤，可以用到更广泛的应用场景中。 比如，在聊天机器人方面，如果用户告诉机器人：“给我妈妈 Jane 预订一张机票，1 月 1 号伦敦飞纽约的”，机器人可以用这种分析方法解读这个指令：</p><p><strong>动作</strong>: 预订<br><strong>动作的对象</strong>: 机票<br><strong>乘客</strong>: Jane<br><strong>出发地</strong>: 伦敦<br><strong>目的地</strong>: 纽约<br><strong>日期</strong>: （明年）1 月 1 号</p><p>树库 treebank 指由许多预先标注好的 树 tree 构成的语料库。现在已经有面向多种语言的树库，既有开源的，也有限定条件下才能免费使用的，以及商用的。其中使用最广泛的是面向英语的宾州树库。宾州树库取材于 华尔街日报 Wall Street Journal 。NLTK 也包含了宾州树库作为一个子语料库。下面是一些使用 树库 treebank 的方法：</p><pre tabindex=0><code>words = nltk.corpus.treebank.words()
print(len(words), &#34;words:&#34;)
print(words)

tagged_sents = nltk.corpus.treebank.tagged_sents()
print(len(tagged_sents), &#34;sentences:&#34;)
print(tagged_sents)
</code></pre><pre tabindex=0><code>100676 words:
[&#39;Pierre&#39;, &#39;Vinken&#39;, &#39;,&#39;, &#39;61&#39;, &#39;years&#39;, &#39;old&#39;, &#39;,&#39;, ...]
3914 sentences:
[[(&#39;Pierre&#39;, &#39;NNP&#39;), (&#39;Vinken&#39;, &#39;NNP&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;61&#39;, &#39;CD&#39;), (&#39;years&#39;, &#39;NNS&#39;), (&#39;old&#39;, &#39;JJ&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;will&#39;, &#39;MD&#39;), (&#39;join&#39;, &#39;VB&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;board&#39;, &#39;NN&#39;), (&#39;as&#39;, &#39;IN&#39;), (&#39;a&#39;, &#39;DT&#39;), (&#39;nonexecutive&#39;, &#39;JJ&#39;), (&#39;director&#39;, &#39;NN&#39;), ...]
</code></pre><p>查看一个句子里的各个 标签 tags ：</p><pre tabindex=0><code>sent0 = tagged_sents[0]
pprint(sent0)
</code></pre><pre tabindex=0><code>[(&#39;Pierre&#39;, &#39;NNP&#39;),
 (&#39;Vinken&#39;, &#39;NNP&#39;),
 (&#39;,&#39;, &#39;,&#39;),
 (&#39;61&#39;, &#39;CD&#39;),
 (&#39;years&#39;, &#39;NNS&#39;),
...
</code></pre><p>定义一个 语法 grammar 来把这个句子转换成树状结构：</p><pre tabindex=0><code>grammar = &#39;&#39;&#39;
    Subject: {&lt;NNP&gt;&lt;NNP&gt;}
    SubjectInfo: {&lt;CD&gt;&lt;NNS&gt;&lt;JJ&gt;}
    Action: {&lt;MD&gt;&lt;VB&gt;}
    Object: {&lt;DT&gt;&lt;NN&gt;}
    Stopwords: {&lt;IN&gt;&lt;DT&gt;}
    ObjectInfo: {&lt;JJ&gt;&lt;NN&gt;}
    When: {&lt;NNP&gt;&lt;CD&gt;}
&#39;&#39;&#39;
parser = nltk.RegexpParser(grammar)
tree = parser.parse(sent0)
print(tree)
</code></pre><pre tabindex=0><code>(S
  (Subject Pierre/NNP Vinken/NNP)
  ,/,
  (SubjectInfo 61/CD years/NNS old/JJ)
  ,/,
  (Action will/MD join/VB)
  (Object the/DT board/NN)
  as/IN
  a/DT
  (ObjectInfo nonexecutive/JJ director/NN)
  (Subject Nov./NNP)
  29/CD
  ./.)
</code></pre><p>图形化地显示：</p><pre tabindex=0><code>tree.draw()
</code></pre><p><img src=https://img.linux.net.cn/data/attachment/album/202107/21/115645kama1atb5maab93a.jpg alt="NLP Treebank image" title="NLP Treebank image"></p><p>树 trees 和 树库 treebanks 的概念是文本分析的一个强大的组成部分。</p><h4 id=自主尝试-2>自主尝试</h4><p>使用 Python 库，下载维基百科的 “<a href=https://en.wikipedia.org/wiki/Open_source>open source</a>” 页面，将得到的文本以图形化的树状结构展现出来。</p><h3 id=命名实体识别>命名实体识别</h3><p>无论口语还是书面语都包含着重要数据。文本处理的主要目标之一，就是提取出关键数据。几乎所有应用场景所需要提取关键数据，比如航空公司的订票机器人或者问答机器人。 NLTK 为此提供了一个 命名实体识别 named entity recognition 的功能。</p><p>这里有一个代码示例：</p><pre tabindex=0><code>sentence = &#39;Peterson first suggested the name &#34;open source&#34; at Palo Alto, California&#39;
</code></pre><p>验证这个句子里的 人名 name 和 地名 place 有没有被识别出来。照例先预处理：</p><pre tabindex=0><code>import nltk

words = nltk.word_tokenize(sentence)
pos_tagged = nltk.pos_tag(words)
</code></pre><p>运行 命名实体标注器 named-entity tagger ：</p><pre tabindex=0><code>ne_tagged = nltk.ne_chunk(pos_tagged)
print(&#34;NE tagged text:&#34;)
print(ne_tagged)
print()
</code></pre><pre tabindex=0><code>NE tagged text:
(S
  (PERSON Peterson/NNP)
  first/RB
  suggested/VBD
  the/DT
  name/NN
  ``/``
  open/JJ
  source/NN
  &#39;&#39;/&#39;&#39;
  at/IN
  (FACILITY Palo/NNP Alto/NNP)
  ,/,
  (GPE California/NNP))
</code></pre><p>上面的结果里，命名实体被识别出来并做了标注；只提取这个 树 tree 里的命名实体：</p><pre tabindex=0><code>print(&#34;Recognized named entities:&#34;)
for ne in ne_tagged:
    if hasattr(ne, &#34;label&#34;):
        print(ne.label(), ne[0:])
</code></pre><pre tabindex=0><code>Recognized named entities:
PERSON [(&#39;Peterson&#39;, &#39;NNP&#39;)]
FACILITY [(&#39;Palo&#39;, &#39;NNP&#39;), (&#39;Alto&#39;, &#39;NNP&#39;)]
GPE [(&#39;California&#39;, &#39;NNP&#39;)]
</code></pre><p>图形化地显示：</p><pre tabindex=0><code>ne_tagged.draw()
</code></pre><p><img src=https://img.linux.net.cn/data/attachment/album/202107/21/115645ghz7j75kwzls2gj5.jpg alt="NLTK Treebank tree" title="NLTK Treebank tree"></p><p>NLTK 内置的 命名实体标注器 named-entity tagger ，使用的是宾州法尼亚大学的 <a href=https://www.ldc.upenn.edu/collaborations/past-projects/ace>Automatic Content Extraction</a>（ACE）程序。该标注器能够识别 组织机构 ORGANIZATION 、人名 PERSON 、地名 LOCATION 、设施 FACILITY 和 地缘政治实体 geopolitical entity 等常见 实体 entites 。</p><p>NLTK 也可以使用其他 标注器 tagger ，比如 <a href=https://nlp.stanford.edu/software/CRF-NER.html>Stanford Named Entity Recognizer</a>. 这个经过训练的标注器用 Java 写成，但 NLTK 提供了一个使用它的接口（详情请查看 <a href=https://www.nltk.org/_modules/nltk/parse/stanford.html>nltk.parse.stanford</a> 或 <a href=https://www.nltk.org/_modules/nltk/tag/stanford.html>nltk.tag.stanford</a>）。</p><h4 id=自主尝试-3>自主尝试</h4><p>使用 Python 库，下载维基百科的 “<a href=https://en.wikipedia.org/wiki/Open_source>open source</a>” 页面，并识别出对 开源 open source 有影响力的人的名字，以及他们为 开源 open source 做贡献的时间和地点。</p><h3 id=高级实践>高级实践</h3><p>如果你准备好了，尝试用这篇文章以及此前的文章介绍的知识构建一个 超级结构 superstructure 。</p><p>使用 Python 库，下载维基百科的 “<a href=https://en.wikipedia.org/wiki/Category:Computer_science>Category: Computer science page</a>”，然后：</p><ul><li>找出其中频率最高的 单词 unigrams 、二元搭配 bigrams 和 三元搭配 trigrams ，将它们作为一个关键词列表或者技术列表。相关领域的学生或者工程师需要了解这样一份列表里的内容。</li><li>图形化地显示这个领域里重要的人名、技术、日期和地点。这会是一份很棒的信息图。</li><li>构建一个搜索引擎。你的搜索引擎性能能够超过维基百科吗？</li></ul><h3 id=下一步>下一步？</h3><p>自然语言处理是 应用构建 application building 的典型支柱。NLTK 是经典、丰富且强大的工具集，提供了为现实世界构建有吸引力、目标明确的应用的工作坊。</p><p>在这个系列的文章里，我用 NLTK 作为例子，展示了自然语言处理可以做什么。自然语言处理和 NLTK 还有太多东西值得探索，这个系列的文章只是帮助你探索它们的切入点。</p><p>如果你的需求增长到 NLTK 已经满足不了了，你可以训练新的模型或者向 NLTK 添加新的功能。基于 NLTK 构建的新的自然语言处理库正在不断涌现，机器学习也正被深度用于自然语言处理。</p><hr><p>via: <a href=https://opensource.com/article/20/8/nlp-python-nltk>https://opensource.com/article/20/8/nlp-python-nltk</a></p><p>作者：<a href=https://opensource.com/users/gammay>Girish Managoli</a> 选题：<a href=https://github.com/lujun9972>lujun9972</a> 译者：<a href=https://github.com/tanloong>tanloong</a> 校对：<a href=https://github.com/wxy>wxy</a></p><p>本文由 <a href=https://github.com/LCTT/TranslateProject>LCTT</a> 原创编译，<a href=https://linux.cn/>Linux中国</a> 荣誉推出</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/nlp/ rel=tag>NLP</a></li><li class=tags__item><a class="tags__link btn" href=/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/ rel=tag>自然语言处理</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Linux.cn Archive.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>