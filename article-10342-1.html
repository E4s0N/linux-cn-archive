<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>数据科学家的命令行技巧 - Linux.cn Archive</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="数据科学家的命令行技巧"><meta property="og:description" content="立志掌握命令行应该在每个开发人员的学习清单上，特别是数据科学家。"><meta property="og:type" content="article"><meta property="og:url" content="/article-10342-1.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-12-13T22:11:41+00:00"><meta property="article:modified_time" content="2018-12-13T22:11:41+00:00"><meta itemprop=name content="数据科学家的命令行技巧"><meta itemprop=description content="立志掌握命令行应该在每个开发人员的学习清单上，特别是数据科学家。"><meta itemprop=datePublished content="2018-12-13T22:11:41+00:00"><meta itemprop=dateModified content="2018-12-13T22:11:41+00:00"><meta itemprop=wordCount content="1045"><meta itemprop=keywords content="命令行,数据科学,"><link rel=preconnect href=https://fonts.bunny.net crossorigin><link rel=dns-prefetch href=//fonts.bunny.net><link rel=dns-prefetch href=//fonts.bunny.net><link rel=stylesheet href="https://fonts.bunny.net/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Linux.cn Archive" rel=home><div class="logo__item logo__text"><div class=logo__title>Linux.cn Archive</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href=/categories/><span class=menu__text>Categories</span></a></li><li class=menu__item><a class=menu__link href=/tags/><span class=menu__text>Tags</span></a></li><li class=menu__item><a class=menu__link href><span class=menu__text>RSS</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>数据科学家的命令行技巧</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2018-12-13T22:11:41Z>December 13, 2018</time></div></div></header><div class="content post__content clearfix"><p><img src=/data/attachment/album/201812/13/221149dirhh8vthq2vll9j.png alt></p><p>对于许多数据科学家来说，数据操作从始至终就是 Pandas 或 Tidyverse。从理论上讲，这样做没有任何问题。毕竟，这就是这些工具存在的原因。然而，对于像分隔符转换这样的简单任务，这些工具是大材小用了。</p><p>立志掌握命令行应该在每个开发人员的学习清单上，特别是数据科学家。学习 shell 的来龙去脉将无可否认地提高你的生产力。除此之外，命令行还是计算领域的一个重要历史课程。例如，awk —— 一种数据驱动的脚本语言。1977 年，在 <a href=https://en.wikipedia.org/wiki/Brian_Kernighan>Brain Kernighan</a>（即传奇的 <a href=https://en.wikipedia.org/wiki/The_C_Programming_Language>K&amp;R 书</a>中 K）的帮助下，awk 首次出现。今天，大约五十年过去了，awk 仍然活跃在每年<a href=https://www.amazon.com/Learning-AWK-Programming-cutting-edge-text-processing-ebook/dp/B07BT98HDS>新出版的书</a>里面。因此，可以安全地假设对命令行魔法的付出不会很快贬值。</p><h3 id=我们将涵盖什么>我们将涵盖什么</h3><ul><li>ICONV</li><li>HEAD</li><li>TR</li><li>WC</li><li>SPLIT</li><li>SORT & UNIQ</li><li>CUT</li><li>PASTE</li><li>JOIN</li><li>GREP</li><li>SED</li><li>AWK</li></ul><h3 id=iconv>ICONV</h3><p>文件编码可能会很棘手。现在大部分文件都是 UTF-8 编码的。要了解 UTF-8 背后的一些魔力，请查看这个出色的<a href="https://www.youtube.com/watch?v=MijmeoH9LT4">视频</a>。尽管如此，有时我们收到的文件不是这种编码。这可能引起对改变编码模式的一些胡乱尝试。这里，<code>iconv</code> 是一个拯救者。<code>iconv</code> 是一个简单的程序，它将获取采用一种编码的文本并输出采用另一种编码的文本。</p><pre tabindex=0><code># Converting -f (from) latin1 (ISO-8859-1)
# -t (to) standard UTF_8

iconv -f ISO-8859-1 -t UTF-8 &lt; input.txt &gt; output.txt
</code></pre><p>实用选项：</p><ul><li><code>iconv -l</code> 列出所有已知编码</li><li><code>iconv -c</code> 默默丢弃无法转换的字符</li></ul><h3 id=head>HEAD</h3><p>如果你是一个 Pandas 重度用户，那么会很熟悉 <code>head</code>。通常在处理新数据时，我们想做的第一件事就是了解其内容。这就得启动 Pandas，读取数据然后调用 <code>df.head()</code> —— 要说这有点费劲。没有任何选项的 <code>head</code> 将打印出文件的前 10 行。<code>head</code> 的真正力量在于干净利落的测试操作。例如，如果我们想将文件的分隔符从逗号更改为管道。一个快速测试将是：<code>head mydata.csv | sed 's/,/|/g'</code>。</p><pre tabindex=0><code># Prints out first 10 lines
head filename.csv

# Print first 3 lines
head -n 3 filename.csv
</code></pre><p>实用选项：</p><ul><li><code>head -n</code> 打印特定行数</li><li><code>head -c</code> 打印特定字节数</li></ul><h3 id=tr>TR</h3><p><code>tr</code> 类似于翻译。这个功能强大的实用程序是文件基础清理的主力。理想的用例是替换文件中的分隔符。</p><pre tabindex=0><code># Converting a tab delimited file into commas
cat tab_delimited.txt | tr &#34;\t&#34; &#34;,&#34; comma_delimited.csv
</code></pre><p><code>tr</code> 另一个功能是你可以用内建 <code>[:class:]</code> 变量（POSIX 字符类）发挥威力。这些包括了：</p><ul><li><code>[:alnum:]</code> 所有字母和数字</li><li><code>[:alpha:]</code> 所有字母</li><li><code>[:blank:]</code> 所有水平空白</li><li><code>[:cntrl:]</code> 所有控制字符</li><li><code>[:digit:]</code> 所有数字</li><li><code>[:graph:]</code> 所有可打印字符，但不包括空格</li><li><code>[:lower:]</code> 所有小写字母</li><li><code>[:print:]</code> 所有可打印字符，包括空格</li><li><code>[:punct:]</code> 所有标点符号</li><li><code>[:space:]</code> 所有水平或垂直空白</li><li><code>[:upper:]</code> 所有大写字母</li><li><code>[:xdigit:]</code> 所有 16 进制数字</li></ul><p>你可以将这些连接在一起以组成强大的程序。以下是一个基本的字数统计程序，可用于检查 README 是否被滥用。</p><pre tabindex=0><code>cat README.md | tr &#34;[:punct:][:space:]&#34; &#34;\n&#34; | tr &#34;[:upper:]&#34; &#34;[:lower:]&#34; | grep . | sort | uniq -c | sort -nr
</code></pre><p>另一个使用基本正则表达式的例子：</p><pre tabindex=0><code># Converting all upper case letters to lower case
cat filename.csv | tr &#39;[A-Z]&#39; &#39;[a-z]&#39;
</code></pre><p>实用选项：</p><ul><li><code>tr -d</code> 删除字符</li><li><code>tr -s</code> 压缩字符</li><li><code>\b</code> 退格</li><li><code>\f</code> 换页</li><li><code>\v</code> 垂直制表符</li><li><code>\NNN</code> 八进制字符</li></ul><h3 id=wc>WC</h3><p>单词计数。它的价值主要来自其 <code>-l</code> 选项，它会给你提供行数。</p><pre tabindex=0><code># Will return number of lines in CSV
wc -l gigantic_comma.csv
</code></pre><p>这个工具可以方便地确认各种命令的输出。所以，如果我们在转换文件中的分隔符之后运行 <code>wc -l</code>，我们会期待总行数是一样的，如果不一致，我们就知道有地方出错了。</p><p>实用选项：</p><ul><li><code>wc -c</code> 打印字节数</li><li><code>wc -m</code> 打印字符数</li><li><code>wc -L</code> 打印最长行的长度</li><li><code>wc -w</code> 打印单词数量</li></ul><h3 id=split>SPLIT</h3><p>文件大小的范围可以很广。对于有的任务，拆分文件或许是有好处的，所以使用 <code>split</code> 吧。<code>split</code> 的基本语法是：</p><pre tabindex=0><code># We will split our CSV into new_filename every 500 lines
split -l 500 filename.csv new_filename_
# filename.csv
# ls output
# new_filename_aaa
# new_filename_aab
# new_filename_aa
</code></pre><p>它有两个奇怪的地方是命名约定和缺少文件扩展名。后缀约定可以通过 <code>-d</code> 标志变为数字。要添加文件扩展名，你需要运行以下 <code>find</code> 命令。它将通过附加 <code>.csv</code> 扩展名来更改当前目录中所有文件的名称，所以小心了。</p><pre tabindex=0><code>find . -type f -exec mv &#39;{}&#39; &#39;{}&#39;.csv \;
# ls output
# filename.csv.csv
# new_filename_aaa.csv
# new_filename_aab.csv
# new_filename_aac.csv
</code></pre><p>实用选项：</p><ul><li><code>split -b N</code> 按特定字节大小分割</li><li><code>split -a N</code> 生成长度为 N 的后缀</li><li><code>split -x</code> 使用十六进制后缀</li></ul><h3 id=sort--uniq>SORT & UNIQ</h3><p>上面两个命令很明显：它们的作用就是字面意思。这两者结合起来可以提供最强大的冲击 (例如，唯一单词的数量)。这是由于 <code>uniq</code> 只作用于重复的相邻行。这也是在输出前进行 <code>sort</code> 的原因。一个有趣的事情是 <code>sort -u</code> 会达到和典型的 <code>sort file.txt | uniq</code> 模式一样的结果。</p><p><code>sort</code> 对数据科学家来说确实具有潜在的有用能力：能够根据特定列对整个 CSV 进行排序。</p><pre tabindex=0><code># Sorting a CSV file by the second column alphabetically
sort -t&#34;,&#34; -k2,2 filename.csv

# Numerically
sort -t&#34;,&#34; -k2n,2 filename.csv

# Reverse order
sort -t&#34;,&#34; -k2nr,2 filename.csv
</code></pre><p>这里的 <code>-t</code> 选项将逗号指定为分隔符，通常假设分隔符是空格或制表符。此外，<code>-k</code> 选项是为了确定我们的键。这里的语法是 <code>-km,n</code>，<code>m</code> 作为开始列，<code>n</code> 作为结束列。</p><p>实用选项：</p><ul><li><code>sort -f</code> 忽略大小写</li><li><code>sort -r</code> 反向排序</li><li><code>sort -R</code> 乱序</li><li><code>uniq -c</code> 统计出现次数</li><li><code>uniq -d</code> 只打印重复行</li></ul><h3 id=cut>CUT</h3><p><code>cut</code> 用于删除列。作为演示，如果我们只想删除第一和第三列。</p><pre tabindex=0><code>cut -d, -f 1,3 filename.csv
</code></pre><p>要选择除了第一行外的所有行。</p><pre tabindex=0><code>cut -d, -f 2- filename.csv
</code></pre><p>结合其他命令，将 <code>cut</code> 用作过滤器。</p><pre tabindex=0><code># Print first 10 lines of column 1 and 3, where &#34;some_string_value&#34; is present
head filename.csv | grep &#34;some_string_value&#34; | cut -d, -f 1,3
</code></pre><p>查出第二列中唯一值的数量。</p><pre tabindex=0><code>cat filename.csv | cut -d, -f 2 | sort | uniq | wc -l

# Count occurences of unique values, limiting to first 10 results
cat filename.csv | cut -d, -f 2 | sort | uniq -c | head
</code></pre><h3 id=paste>PASTE</h3><p><code>paste</code> 是一个带有趣味性功能的特定命令。如果你有两个需要合并的文件，并且它们已经排序好了，<code>paste</code> 帮你解决了接下来的步骤。</p><pre tabindex=0><code># names.txt
adam
john
zach

# jobs.txt
lawyer
youtuber
developer

# Join the two into a CSV
paste -d &#39;,&#39; names.txt jobs.txt &gt; person_data.txt

# Output
adam,lawyer
john,youtuber
zach,developer
</code></pre><p>更多 SQL 式变种，见下文。</p><h3 id=join>JOIN</h3><p><code>join</code> 是一个简单的、 准切向的 quasi-tangential SQL。最大的区别是 <code>join</code> 将返回所有列以及只能在一个字段上匹配。默认情况下，<code>join</code> 将尝试使用第一列作为匹配键。为了获得不同结果，必须使用以下语法：</p><pre tabindex=0><code># Join the first file (-1) by the second column
# and the second file (-2) by the first
join -t &#34;,&#34; -1 2 -2 1 first_file.txt second_file.txt
</code></pre><p>标准的 <code>join</code> 是内连接。然而，外连接通过 <code>-a</code> 选项也是可行的。另一个值得一提的技巧是 <code>-q</code> 标志，如果发现有缺失的字段，可用于替换值。</p><pre tabindex=0><code># Outer join, replace blanks with NULL in columns 1 and 2
# -o which fields to substitute - 0 is key, 1.1 is first column, etc...
join -t&#34;,&#34; -1 2 -a 1 -a2 -e &#39; NULL&#39; -o &#39;0,1.1,2.2&#39; first_file.txt second_file.txt
</code></pre><p>它不是最用户友好的命令，而是绝望时刻的绝望措施。</p><p>实用选项：</p><ul><li><code>join -a</code> 打印不可配对的行</li><li><code>join -e</code> 替换丢失的输入字段</li><li><code>join -j</code> 相当于 <code>-1 FIELD -2 FIELD</code></li></ul><h3 id=grep>GREP</h3><p><code>grep</code> 即 用正则表达式全局搜索并且打印 Global search for a Regular Expression and Print ，可能是最有名的命令，并且名副其实。<code>grep</code> 很强大，特别适合在大型代码库中查找。在数据科学的王国里，它充当其他命令的提炼机制。虽然它的标准用途也很有价值。</p><pre tabindex=0><code># Recursively search and list all files in directory containing &#39;word&#39;

grep -lr &#39;word&#39; .

# List number of files containing word

grep -lr &#39;word&#39; . | wc -l
</code></pre><p>计算包含单词或模式的总行数。</p><pre tabindex=0><code>grep -c &#39;some_value&#39; filename.csv

# Same thing, but in all files in current directory by file name

grep -c &#39;some_value&#39; *
</code></pre><p>对多个值使用“或”运算符： <code>\|</code>。</p><pre tabindex=0><code>grep &#34;first_value\|second_value&#34; filename.csv
</code></pre><p>实用选项：</p><ul><li><code>alias grep="grep --color=auto"</code> 使 grep 色彩丰富</li><li><code>grep -E</code> 使用扩展正则表达式</li><li><code>grep -w</code> 只匹配整个单词</li><li><code>grep -l</code> 打印匹配的文件名</li><li><code>grep -v</code> 非匹配</li></ul><h3 id=大人物们>大人物们</h3><p><code>sed</code> 和 <code>awk</code> 是本文中最强大的两个命令。为简洁起见，我不打算详细讨论这两个命令。相反，我将介绍各种能证明其令人印象深刻的力量的命令。如果你想了解更多，<a href="https://www.amazon.com/sed-awk-Dale-Dougherty/dp/1565922255/ref=sr_1_1?ie=UTF8&amp;qid=1524381457&amp;sr=8-1&amp;keywords=sed+and+awk">这儿就有一本书</a>是关于它们的。</p><h3 id=sed>SED</h3><p><code>sed</code> 本质上是一个流编辑器。它擅长替换，但也可以用于所有输出重构。</p><p>最基本的 <code>sed</code> 命令由 <code>s/old/new/g</code> 组成。它的意思是搜索 <code>old</code>，全局替换为 <code>new</code>。 如果没有 <code>/g</code>，我们的命令将在 <code>old</code> 第一次出现后终止。</p><p>为了快速了解它的功能，我们可以深入了解一个例子。 在以下情景中，你已有以下文件：</p><pre tabindex=0><code>balance,name
$1,000,john
$2,000,jack
</code></pre><p>我们可能想要做的第一件事是删除美元符号。<code>-i</code> 标志表示原位。<code>''</code> 表示零长度文件扩展名，从而覆盖我们的初始文件。理想情况下，你可以单独测试，然后输出到新文件。</p><pre tabindex=0><code>sed -i &#39;&#39; &#39;s/\$//g&#39; data.txt
# balance,name
# 1,000,john
# 2,000,jack
</code></pre><p>接下来，去除 <code>blance</code> 列的逗号。</p><pre tabindex=0><code>sed -i &#39;&#39; &#39;s/\([0-9]\),\([0-9]\)/\1\2/g&#39; data.txt
# balance,name
# 1000,john
# 2000,jack
</code></pre><p>最后 jack 有一天决定辞职。所以，再见了，我的朋友。</p><pre tabindex=0><code>sed -i &#39;&#39; &#39;/jack/d&#39; data.txt
# balance,name
# 1000,john
</code></pre><p>正如你所看到的，<code>sed</code> 有很多强大的功能，但乐趣并不止于此。</p><h3 id=awk>AWK</h3><p>最好的留在最后。<code>awk</code> 不仅仅是一个简单的命令：它是一个成熟的语言。在本文中涉及的所有内容中，<code>awk</code> 是目前为止最酷的。如果你感兴趣，这里有很多很棒的资源 —— 看 <a href="https://www.amazon.com/AWK-Programming-Language-Alfred-Aho/dp/020107981X/ref=sr_1_1?ie=UTF8&amp;qid=1524388936&amp;sr=8-1&amp;keywords=awk">这里</a>、<a href=http://www.grymoire.com/Unix/Awk.html>这里</a> 和 <a href=https://www.tutorialspoint.com/awk/index.htm>这里</a>。</p><p><code>awk</code> 的常见用例包括：</p><ul><li>文字处理</li><li>格式化文本报告</li><li>执行算术运算</li><li>执行字符串操作</li></ul><p><code>awk</code> 可以以最原生的形式并行 <code>grep</code>。</p><pre tabindex=0><code>awk &#39;/word/&#39; filename.csv
</code></pre><p>或者更加神奇：将 <code>grep</code> 和 <code>cut</code> 组合起来。在这里，对于所有带我们指定单词 <code>word</code> 的行，<code>awk</code> 打印第三和第四列，用 <code>tab</code> 分隔。<code>-F,</code> 用于指定切分时的列分隔符为逗号。</p><pre tabindex=0><code>awk -F, &#39;/word/ { print $3 &#34;\t&#34; $4 }&#39; filename.csv
</code></pre><p><code>awk</code> 内置了许多精巧的变量。比如，<code>NF</code> —— 字段数，和 <code>NR</code> —— 记录数。要获取文件中的第 53 条记录：</p><pre tabindex=0><code>awk -F, &#39;NR == 53&#39; filename.csv
</code></pre><p>更多的花招是其基于一个或多个值进行过滤的能力。下面的第一个示例将打印第一列等于给定字符串的行的行号和列。</p><pre tabindex=0><code>awk -F, &#39; $1 == &#34;string&#34; { print NR, $0 } &#39; filename.csv

# Filter based off of numerical value in second column
awk -F, &#39; $2 == 1000 { print NR, $0 } &#39; filename.csv
</code></pre><p>多个数值表达式：</p><pre tabindex=0><code># Print line number and columns where column three greater
# than 2005 and column five less than one thousand

awk -F, &#39; $3 &gt;= 2005 &amp;&amp; $5 &lt;= 1000 { print NR, $0 } &#39; filename.csv
</code></pre><p>求出第三列的总和：</p><pre tabindex=0><code>awk -F, &#39;{ x+=$3 } END { print x }&#39; filename.csv
</code></pre><p>在第一列等于 <code>something</code> 的那些行，求出第三列值的总和。</p><pre tabindex=0><code>awk -F, &#39;$1 == &#34;something&#34; { x+=$3 } END { print x }&#39; filename.csv
</code></pre><p>获取文件的行列数：</p><pre tabindex=0><code>awk -F, &#39;END { print NF, NR }&#39; filename.csv

# Prettier version
awk -F, &#39;BEGIN { print &#34;COLUMNS&#34;, &#34;ROWS&#34; }; END { print NF, NR }&#39; filename.csv
</code></pre><p>打印出现了两次的行：</p><pre tabindex=0><code>awk -F, &#39;++seen[$0] == 2&#39; filename.csv
</code></pre><p>删除重复的行：</p><pre tabindex=0><code># Consecutive lines
awk &#39;a !~ $0; {a=$0}&#39;]

# Nonconsecutive lines
awk &#39;! a[$0]++&#39; filename.csv

# More efficient
awk &#39;!($0 in a) {a[$0];print}
</code></pre><p>使用内置函数 <code>gsub()</code> 替换多个值。</p><pre tabindex=0><code>awk &#39;{gsub(/scarlet|ruby|puce/, &#34;red&#34;); print}&#39;
</code></pre><p>这个 <code>awk</code> 命令将组合多个 CSV 文件，忽略标题，然后在最后附加它。</p><pre tabindex=0><code>awk &#39;FNR==1 &amp;&amp; NR!=1{next;}{print}&#39; *.csv &gt; final_file.csv
</code></pre><p>需要缩小一个庞大的文件？ <code>awk</code> 可以在 <code>sed</code> 的帮助下处理它。具体来说，该命令根据行数将一个大文件分成多个较小的文件。这个一行脚本将增加一个扩展名。</p><pre tabindex=0><code>sed &#39;1d;$d&#39; filename.csv | awk &#39;NR%NUMBER_OF_LINES==1{x=&#34;filename-&#34;++i&#34;.csv&#34;;}{print &gt; x}&#39;

# Example: splitting big_data.csv into data_(n).csv every 100,000 lines
sed &#39;1d;$d&#39; big_data.csv | awk &#39;NR%100000==1{x=&#34;data_&#34;++i&#34;.csv&#34;;}{print &gt; x}&#39;
</code></pre><h3 id=结语>结语</h3><p>命令行拥有无穷无尽的力量。本文中介绍的命令足以将你从一无所知提升到英雄人物。除了涵盖的内容之外，还有许多实用程序可以考虑用于日常数据操作。<a href=http://csvkit.readthedocs.io/en/1.0.3/>Csvkit</a>、<a href=https://github.com/BurntSushi/xsv>xsv</a> 还有 <a href=https://github.com/harelba/q>q</a> 是需要记住的三个。如果你希望更深入地了解命令行数据科学，查看<a href="https://www.amazon.com/Data-Science-Command-Line-Time-Tested/dp/1491947853/ref=sr_1_1?ie=UTF8&amp;qid=1524390894&amp;sr=8-1&amp;keywords=data+science+at+the+command+line">这本书</a>。它也可以<a href=https://www.datascienceatthecommandline.com/>免费</a>在线获得！</p><hr><p>via: <a href=http://kadekillary.work/post/cli-4-ds/>http://kadekillary.work/post/cli-4-ds/</a></p><p>作者：<a href=http://kadekillary.work/authors/kadekillary>Kade Killary</a> 选题：<a href=https://github.com/lujun9972>lujun9972</a> 译者：<a href=https://github.com/graveaccent>GraveAccent</a> 校对：<a href=https://github.com/wxy>wxy</a></p><p>本文由 <a href=https://github.com/LCTT/TranslateProject>LCTT</a> 原创编译，<a href=https://linux.cn/>Linux中国</a> 荣誉推出</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/ rel=tag>命令行</a></li><li class=tags__item><a class="tags__link btn" href=/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/ rel=tag>数据科学</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Linux.cn Archive.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>