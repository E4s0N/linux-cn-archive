<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>如何在Ubuntu 14.04 LTS安装网络爬虫工具：Scrapy - Linux.cn Archive</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="如何在Ubuntu 14.04 LTS安装网络爬虫工具：Scrapy"><meta property="og:description" content="这是一款提取网站数据的开源工具。Scrapy框架用Python开发而成，它使抓取工作又快又简单，且可扩展。我们已经在virtual box中创建一台虚拟机（VM）并且在上面安装了Ubuntu 14.04 LTS。 安装 Scrapy  Scrapy依赖于Python、开发库和pip。Python最新的版本已经在Ubuntu上预装了。因此我们在安装Scrapy之前只需安装pip和python开发库就可以了。 pip是作为python包索引器easy_install的替代品，用于安装和管理Python包。pip包的安装可见图 1。 sudo apt-get install python-pip   图:1 pip安装 我们必须要用下面的命令安装python开发库。如果包"><meta property="og:type" content="article"><meta property="og:url" content="/article-5098-1.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2015-03-21T17:42:00+00:00"><meta property="article:modified_time" content="2015-03-21T17:42:00+00:00"><meta itemprop=name content="如何在Ubuntu 14.04 LTS安装网络爬虫工具：Scrapy"><meta itemprop=description content="这是一款提取网站数据的开源工具。Scrapy框架用Python开发而成，它使抓取工作又快又简单，且可扩展。我们已经在virtual box中创建一台虚拟机（VM）并且在上面安装了Ubuntu 14.04 LTS。 安装 Scrapy  Scrapy依赖于Python、开发库和pip。Python最新的版本已经在Ubuntu上预装了。因此我们在安装Scrapy之前只需安装pip和python开发库就可以了。 pip是作为python包索引器easy_install的替代品，用于安装和管理Python包。pip包的安装可见图 1。 sudo apt-get install python-pip   图:1 pip安装 我们必须要用下面的命令安装python开发库。如果包"><meta itemprop=datePublished content="2015-03-21T17:42:00+00:00"><meta itemprop=dateModified content="2015-03-21T17:42:00+00:00"><meta itemprop=wordCount content="175"><meta itemprop=keywords content="Python,Scrapy,爬虫,"><link rel=preconnect href=https://fonts.bunny.net crossorigin><link rel=dns-prefetch href=//fonts.bunny.net><link rel=dns-prefetch href=//fonts.bunny.net><link rel=stylesheet href="https://fonts.bunny.net/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Linux.cn Archive" rel=home><div class="logo__item logo__text"><div class=logo__title>Linux.cn Archive</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href=/categories/><span class=menu__text>Categories</span></a></li><li class=menu__item><a class=menu__link href=/tags/><span class=menu__text>Tags</span></a></li><li class=menu__item><a class=menu__link href><span class=menu__text>RSS</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>如何在Ubuntu 14.04 LTS安装网络爬虫工具：Scrapy</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2015-03-21T17:42:00Z>March 21, 2015</time></div></div></header><div class="content post__content clearfix"><p>这是一款提取网站数据的开源工具。Scrapy框架用Python开发而成，它使抓取工作又快又简单，且可扩展。我们已经在virtual box中创建一台虚拟机（VM）并且在上面安装了Ubuntu 14.04 LTS。</p><h3 id=安装-scrapy>安装 Scrapy</h3><p><img src=/data/attachment/album/201503/21/174213pc6aqwfzf81qnzga.jpg alt></p><p>Scrapy依赖于Python、开发库和pip。Python最新的版本已经在Ubuntu上预装了。因此我们在安装Scrapy之前只需安装pip和python开发库就可以了。</p><p>pip是作为python包索引器easy_install的替代品，用于安装和管理Python包。pip包的安装可见图 1。</p><pre tabindex=0><code>sudo apt-get install python-pip
</code></pre><p><img src=/data/attachment/album/201503/21/174230mh16gvlvhzzl6urt.png alt="Fig:1 Pip installation"></p><p><em>图:1 pip安装</em></p><p>我们必须要用下面的命令安装python开发库。如果包没有安装那么就会在安装scrapy框架的时候报关于python.h头文件的错误。</p><pre tabindex=0><code>sudo apt-get install python-dev
</code></pre><p><img src=/data/attachment/album/201503/21/174231qahzo63dabnbaby8.png alt="Fig:2 Python Developer Libraries"></p><p><em>图:2 Python 开发库</em></p><p>scrapy框架既可从deb包安装也可以从源码安装。在图3中我们用pip（Python 包管理器）安装了deb包了。</p><pre tabindex=0><code>sudo pip install scrapy 
</code></pre><p><img src=/data/attachment/album/201503/21/174232nb8xy0ylvzb5umnt.png alt="Fig:3 Scrapy Installation"></p><p><em>图:3 Scrapy 安装</em></p><p>图4中scrapy的成功安装需要一些时间。</p><p><img src=/data/attachment/album/201503/21/174234aczsnbic07gsngss.png alt="Fig:4 Successful installation of Scrapy Framework"></p><p><em>图:4 成功安装Scrapy框架</em></p><h3 id=使用scrapy框架提取数据>使用scrapy框架提取数据</h3><h4 id=基础教程>基础教程</h4><p>我们将用scrapy从fatwallet.com上提取商店名称（卖卡的店）。首先，我们使用下面的命令新建一个scrapy项目“store name”， 见图5。</p><pre tabindex=0><code>$sudo scrapy startproject store_name
</code></pre><p><img src=/data/attachment/album/201503/21/174237ldhdytd10yg44hyh.png alt="Fig:5 Creation of new project in Scrapy Framework"></p><p><em>图:5 Scrapy框架新建项目</em></p><p>上面的命令在当前路径创建了一个“store_name”的目录。项目主目录下包含的文件/文件夹见图6。</p><pre tabindex=0><code>$sudo ls –lR store_name
</code></pre><p><img src=/data/attachment/album/201503/21/174240dhzs3aa7df3s0shu.png alt="Fig:6 Contents of store_name project."></p><p><em>图:6 store_name项目的内容</em></p><p>每个文件/文件夹的概要如下：</p><ul><li>scrapy.cfg 是项目配置文件</li><li>store_name/ 主目录下的另一个文件夹。 这个目录包含了项目的python代码</li><li>store_name/items.py 包含了将由蜘蛛爬取的项目</li><li>store_name/pipelines.py 是管道文件</li><li>store_name/settings.py 是项目的配置文件</li><li>store_name/spiders/， 包含了用于爬取的蜘蛛</li></ul><p>由于我们要从fatwallet.com上如提取店名，因此我们如下修改文件（LCTT 译注：这里没说明是哪个文件，译者认为应该是 items.py）。</p><pre tabindex=0><code>import scrapy

class StoreNameItem(scrapy.Item):

   name = scrapy.Field()   #  取出卡片商店的名称
</code></pre><p>之后我们要在项目的store_name/spiders/文件夹下写一个新的蜘蛛。蜘蛛是一个python类，它包含了下面几个必须的属性：</p><ol><li>蜘蛛名 (name )</li><li>爬取起点url (start_urls)</li><li>包含了从响应中提取需要内容相应的正则表达式的解析方法。解析方法对爬虫而言很重要。</li></ol><p>我们在store<em>name/spiders/目录下创建了“store</em>name.py”爬虫，并添加如下的代码来从fatwallet.com上提取店名。爬虫的输出写到文件（<strong>StoreName.txt</strong>）中，见图7。</p><pre tabindex=0><code>from scrapy.selector import Selector
from scrapy.spider import BaseSpider
from scrapy.http import Request
from scrapy.http import FormRequest
import re
class StoreNameItem(BaseSpider):
name = &#34;storename&#34;
allowed_domains = [&#34;fatwallet.com&#34;]
start_urls = [&#34;http://fatwallet.com/cash-back-shopping/&#34;]

def parse(self,response):
output = open(&#39;StoreName.txt&#39;,&#39;w&#39;)
resp = Selector(response)

tags = resp.xpath(&#39;//tr[@class=&#34;storeListRow&#34;]|\
         //tr[@class=&#34;storeListRow even&#34;]|\
         //tr[@class=&#34;storeListRow even last&#34;]|\
          //tr[@class=&#34;storeListRow last&#34;]&#39;).extract()
for i in tags:
i = i.encode(&#39;utf-8&#39;, &#39;ignore&#39;).strip()
store_name = &#39;&#39;
if re.search(r&#34;class=\&#34;storeListStoreName\&#34;&gt;.*?&lt;&#34;,i,re.I|re.S):
store_name = re.search(r&#34;class=\&#34;storeListStoreName\&#34;&gt;.*?&lt;&#34;,i,re.I|re.S).group()
store_name = re.search(r&#34;&gt;.*?&lt;&#34;,store_name,re.I|re.S).group()
store_name = re.sub(r&#39;&gt;&#39;,&#34;&#34;,re.sub(r&#39;&lt;&#39;,&#34;&#34;,store_name,re.I))
store_name = re.sub(r&#39;&amp;amp;&#39;,&#34;&amp;&#34;,re.sub(r&#39;&amp;amp;&#39;,&#34;&amp;&#34;,store_name,re.I))
#print store_name
output.write(store_name+&#34;&#34;+&#34;\n&#34;)
</code></pre><p><img src=/data/attachment/album/201503/21/174242z4g4b5bxg4p9s4ga.png alt="Fig:7 Output of the Spider code ."></p><p><em>图:7 爬虫的输出</em></p><p><em>注意: 本教程的目的仅用于理解scrapy框架</em></p><hr><p>via: <a href=http://linoxide.com/ubuntu-how-to/scrapy-install-ubuntu/>http://linoxide.com/ubuntu-how-to/scrapy-install-ubuntu/</a></p><p>作者：<a href=http://linoxide.com/author/naveeda/>nido</a> 译者：<a href=https://github.com/geekpi>geekpi</a> 校对：<a href=https://github.com/wxy>wxy</a></p><p>本文由 <a href=https://github.com/LCTT/TranslateProject>LCTT</a> 原创翻译，<a href=http://linux.cn/>Linux中国</a> 荣誉推出</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/python/ rel=tag>Python</a></li><li class=tags__item><a class="tags__link btn" href=/tags/scrapy/ rel=tag>Scrapy</a></li><li class=tags__item><a class="tags__link btn" href=/tags/%E7%88%AC%E8%99%AB/ rel=tag>爬虫</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Linux.cn Archive.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>