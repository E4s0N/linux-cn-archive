<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>fdupes：Linux 中查找并删除重复文件的命令行工具 - Linux.cn Archive</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="fdupes：Linux 中查找并删除重复文件的命令行工具"><meta property="og:description" content="对于大多数计算机用户而言，查找并替换重复的文件是一个常见的需求。查找并移除重复文件真是一项令人不胜其烦的工作，它耗时又耗力。但如果你的机器上跑着GNU/Linux，那么查找重复文件会变得十分简单，这多亏了fdupes工具。  fdupes在Linux中查找并删除重复文件 fdupes是啥东东？ fdupes是Linux下的一个工具，它由Adrian Lopez用C编程语言编写并基于MIT许可证发行，该应用程序可以在指定的目录及子目录中查找重复的文件。fdupes通过对比文件的MD5签名，以及逐字节比较文件来识别重复内容，fdupes有各种选项，可以实现对文件的列出、删除、"><meta property="og:type" content="article"><meta property="og:url" content="/article-6127-1.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2015-09-01T14:13:00+00:00"><meta property="article:modified_time" content="2015-09-01T14:13:00+00:00"><meta itemprop=name content="fdupes：Linux 中查找并删除重复文件的命令行工具"><meta itemprop=description content="对于大多数计算机用户而言，查找并替换重复的文件是一个常见的需求。查找并移除重复文件真是一项令人不胜其烦的工作，它耗时又耗力。但如果你的机器上跑着GNU/Linux，那么查找重复文件会变得十分简单，这多亏了fdupes工具。  fdupes在Linux中查找并删除重复文件 fdupes是啥东东？ fdupes是Linux下的一个工具，它由Adrian Lopez用C编程语言编写并基于MIT许可证发行，该应用程序可以在指定的目录及子目录中查找重复的文件。fdupes通过对比文件的MD5签名，以及逐字节比较文件来识别重复内容，fdupes有各种选项，可以实现对文件的列出、删除、"><meta itemprop=datePublished content="2015-09-01T14:13:00+00:00"><meta itemprop=dateModified content="2015-09-01T14:13:00+00:00"><meta itemprop=wordCount content="716"><meta itemprop=keywords content="fdupes,重复,"><link rel=preconnect href=https://fonts.bunny.net crossorigin><link rel=dns-prefetch href=//fonts.bunny.net><link rel=dns-prefetch href=//fonts.bunny.net><link rel=stylesheet href="https://fonts.bunny.net/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Linux.cn Archive" rel=home><div class="logo__item logo__text"><div class=logo__title>Linux.cn Archive</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href=/categories/><span class=menu__text>Categories</span></a></li><li class=menu__item><a class=menu__link href=/tags/><span class=menu__text>Tags</span></a></li><li class=menu__item><a class=menu__link href><span class=menu__text>RSS</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>fdupes：Linux 中查找并删除重复文件的命令行工具</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2015-09-01T14:13:00Z>September 01, 2015</time></div></div></header><div class="content post__content clearfix"><p>对于大多数计算机用户而言，查找并替换重复的文件是一个常见的需求。查找并移除重复文件真是一项令人不胜其烦的工作，它耗时又耗力。但如果你的机器上跑着GNU/Linux，那么查找重复文件会变得十分简单，这多亏了<code>fdupes</code>工具。</p><p><img src=/data/attachment/album/201509/01/111653azfdd8pz0grep0vy.png alt="Find and Delete Duplicate Files in Linux"></p><p><em>fdupes——在Linux中查找并删除重复文件</em></p><h3 id=fdupes是啥东东>fdupes是啥东东？</h3><p><strong>fdupes</strong>是Linux下的一个工具，它由<strong>Adrian Lopez</strong>用C编程语言编写并基于MIT许可证发行，该应用程序可以在指定的目录及子目录中查找重复的文件。fdupes通过对比文件的MD5签名，以及逐字节比较文件来识别重复内容，fdupes有各种选项，可以实现对文件的列出、删除、替换为文件副本的硬链接等操作。</p><p>文件对比以下列顺序开始：</p><p><strong>大小对比 > 部分 MD5 签名对比 > 完整 MD5 签名对比 > 逐字节对比</strong></p><h3 id=安装-fdupes-到-linux>安装 fdupes 到 Linux</h3><p>在基于<strong>Debian</strong>的系统上，如<strong>Ubuntu</strong>和<strong>Linux Mint</strong>，安装最新版fdupes，用下面的命令手到擒来。</p><pre tabindex=0><code>$ sudo apt-get install fdupes
</code></pre><p>在基于CentOS/RHEL和Fedora的系统上，你需要开启<a href=/article-2324-1.html>epel仓库</a>来安装fdupes包。</p><pre tabindex=0><code># yum install fdupes
# dnf install fdupes    [在 Fedora 22 及其以后]
</code></pre><p><strong>注意</strong>：自Fedora 22之后，默认的包管理器yum被dnf取代了。</p><h3 id=fdupes命令如何使用>fdupes命令如何使用</h3><p>1、 作为演示的目的，让我们来在某个目录（比如 tecmint）下创建一些重复文件，命令如下：</p><pre tabindex=0><code>$ mkdir /home/&#34;$USER&#34;/Desktop/tecmint &amp;&amp; cd /home/&#34;$USER&#34;/Desktop/tecmint &amp;&amp; for i in {1..15}; do echo &#34;I Love Tecmint. Tecmint is a very nice community of Linux Users.&#34; &gt; tecmint${i}.txt ; done
</code></pre><p>在执行以上命令后，让我们使用ls<a href=/article-5109-1.html>命令</a>验证重复文件是否创建。</p><pre tabindex=0><code>$ ls -l

total 60
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint10.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint11.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint12.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint13.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint14.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint15.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint1.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint2.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint3.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint4.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint5.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint6.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint7.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint8.txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint9.txt
</code></pre><p>上面的脚本创建了<strong>15</strong>个文件，名称分别为tecmint1.txt，tecmint2.txt……tecmint15.txt，并且每个文件的数据相同，如</p><pre tabindex=0><code>&#34;I Love Tecmint. Tecmint is a very nice community of Linux Users.&#34;
</code></pre><p>2、 现在在<strong>tecmint</strong>文件夹内搜索重复的文件。</p><pre tabindex=0><code>$ fdupes /home/$USER/Desktop/tecmint 

/home/tecmint/Desktop/tecmint/tecmint13.txt
/home/tecmint/Desktop/tecmint/tecmint8.txt
/home/tecmint/Desktop/tecmint/tecmint11.txt
/home/tecmint/Desktop/tecmint/tecmint3.txt
/home/tecmint/Desktop/tecmint/tecmint4.txt
/home/tecmint/Desktop/tecmint/tecmint6.txt
/home/tecmint/Desktop/tecmint/tecmint7.txt
/home/tecmint/Desktop/tecmint/tecmint9.txt
/home/tecmint/Desktop/tecmint/tecmint10.txt
/home/tecmint/Desktop/tecmint/tecmint2.txt
/home/tecmint/Desktop/tecmint/tecmint5.txt
/home/tecmint/Desktop/tecmint/tecmint14.txt
/home/tecmint/Desktop/tecmint/tecmint1.txt
/home/tecmint/Desktop/tecmint/tecmint15.txt
/home/tecmint/Desktop/tecmint/tecmint12.txt
</code></pre><p>3、 使用**-r**选项在每个目录包括其子目录中递归搜索重复文件。</p><p>它会递归搜索所有文件和文件夹，花一点时间来扫描重复文件，时间的长短取决于文件和文件夹的数量。在此其间，终端中会显示全部过程，像下面这样。</p><pre tabindex=0><code>$ fdupes -r /home

Progress [37780/54747] 69%
</code></pre><p>4、 使用**-S**选项来查看某个文件夹内找到的重复文件的大小。</p><pre tabindex=0><code>$ fdupes -S /home/$USER/Desktop/tecmint

65 bytes each:                          
/home/tecmint/Desktop/tecmint/tecmint13.txt
/home/tecmint/Desktop/tecmint/tecmint8.txt
/home/tecmint/Desktop/tecmint/tecmint11.txt
/home/tecmint/Desktop/tecmint/tecmint3.txt
/home/tecmint/Desktop/tecmint/tecmint4.txt
/home/tecmint/Desktop/tecmint/tecmint6.txt
/home/tecmint/Desktop/tecmint/tecmint7.txt
/home/tecmint/Desktop/tecmint/tecmint9.txt
/home/tecmint/Desktop/tecmint/tecmint10.txt
/home/tecmint/Desktop/tecmint/tecmint2.txt
/home/tecmint/Desktop/tecmint/tecmint5.txt
/home/tecmint/Desktop/tecmint/tecmint14.txt
/home/tecmint/Desktop/tecmint/tecmint1.txt
/home/tecmint/Desktop/tecmint/tecmint15.txt
/home/tecmint/Desktop/tecmint/tecmint12.txt
</code></pre><p>5、 你可以同时使用**-S<strong>和</strong>-r**选项来查看所有涉及到的目录和子目录中的重复文件的大小，如下：</p><pre tabindex=0><code>$ fdupes -Sr /home/avi/Desktop/

65 bytes each:                          
/home/tecmint/Desktop/tecmint/tecmint13.txt
/home/tecmint/Desktop/tecmint/tecmint8.txt
/home/tecmint/Desktop/tecmint/tecmint11.txt
/home/tecmint/Desktop/tecmint/tecmint3.txt
/home/tecmint/Desktop/tecmint/tecmint4.txt
/home/tecmint/Desktop/tecmint/tecmint6.txt
/home/tecmint/Desktop/tecmint/tecmint7.txt
/home/tecmint/Desktop/tecmint/tecmint9.txt
/home/tecmint/Desktop/tecmint/tecmint10.txt
/home/tecmint/Desktop/tecmint/tecmint2.txt
/home/tecmint/Desktop/tecmint/tecmint5.txt
/home/tecmint/Desktop/tecmint/tecmint14.txt
/home/tecmint/Desktop/tecmint/tecmint1.txt
/home/tecmint/Desktop/tecmint/tecmint15.txt
/home/tecmint/Desktop/tecmint/tecmint12.txt

107 bytes each:
/home/tecmint/Desktop/resume_files/r-csc.html
/home/tecmint/Desktop/resume_files/fc.html
</code></pre><p>6、 不同于在一个或所有文件夹内递归搜索，你可以选择按要求有选择性地在两个或三个文件夹内进行搜索。不必再提醒你了吧，如有需要，你可以使用**-S<strong>和/或</strong>-r**选项。</p><pre tabindex=0><code>$ fdupes /home/avi/Desktop/ /home/avi/Templates/
</code></pre><p>7、 要删除重复文件，同时保留一个副本，你可以使用<code>-d</code>选项。使用该选项，你必须额外小心，否则最终结果可能会是文件/数据的丢失。郑重提醒，此操作不可恢复。</p><pre tabindex=0><code>$ fdupes -d /home/$USER/Desktop/tecmint

[1] /home/tecmint/Desktop/tecmint/tecmint13.txt
[2] /home/tecmint/Desktop/tecmint/tecmint8.txt
[3] /home/tecmint/Desktop/tecmint/tecmint11.txt
[4] /home/tecmint/Desktop/tecmint/tecmint3.txt
[5] /home/tecmint/Desktop/tecmint/tecmint4.txt
[6] /home/tecmint/Desktop/tecmint/tecmint6.txt
[7] /home/tecmint/Desktop/tecmint/tecmint7.txt
[8] /home/tecmint/Desktop/tecmint/tecmint9.txt
[9] /home/tecmint/Desktop/tecmint/tecmint10.txt
[10] /home/tecmint/Desktop/tecmint/tecmint2.txt
[11] /home/tecmint/Desktop/tecmint/tecmint5.txt
[12] /home/tecmint/Desktop/tecmint/tecmint14.txt
[13] /home/tecmint/Desktop/tecmint/tecmint1.txt
[14] /home/tecmint/Desktop/tecmint/tecmint15.txt
[15] /home/tecmint/Desktop/tecmint/tecmint12.txt

Set 1 of 1, preserve files [1 - 15, all]: 
</code></pre><p>你可能注意到了，所有重复的文件被列了出来，并给出删除提示，一个一个来，或者指定范围，或者一次性全部删除。你可以选择一个范围，就像下面这样，来删除指定范围内的文件。</p><pre tabindex=0><code>Set 1 of 1, preserve files [1 - 15, all]: 2-15

   [-] /home/tecmint/Desktop/tecmint/tecmint13.txt
   [+] /home/tecmint/Desktop/tecmint/tecmint8.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint11.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint3.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint4.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint6.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint7.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint9.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint10.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint2.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint5.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint14.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint1.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint15.txt
   [-] /home/tecmint/Desktop/tecmint/tecmint12.txt
</code></pre><p>8、 从安全角度出发，你可能想要打印<code>fdupes</code>的输出结果到文件中，然后检查文本文件来决定要删除什么文件。这可以降低意外删除文件的风险。你可以这么做：</p><pre tabindex=0><code>$ fdupes -Sr /home &gt; /home/fdupes.txt
</code></pre><p><strong>注意</strong>：你应该替换<code>/home</code>为你想要的文件夹。同时，如果你想要递归搜索并打印大小，可以使用<code>-r</code>和<code>-S</code>选项。</p><p>9、 你可以使用<code>-f</code>选项来忽略每个匹配集中的首个文件。</p><p>首先列出该目录中的文件。</p><pre tabindex=0><code>$ ls -l /home/$USER/Desktop/tecmint

total 20
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint9 (3rd copy).txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint9 (4th copy).txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint9 (another copy).txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint9 (copy).txt
-rw-r--r-- 1 tecmint tecmint 65 Aug  8 11:22 tecmint9.txt
</code></pre><p>然后，忽略掉每个匹配集中的首个文件。</p><pre tabindex=0><code>$ fdupes -f /home/$USER/Desktop/tecmint

/home/tecmint/Desktop/tecmint9 (copy).txt
/home/tecmint/Desktop/tecmint9 (3rd copy).txt
/home/tecmint/Desktop/tecmint9 (another copy).txt
/home/tecmint/Desktop/tecmint9 (4th copy).txt
</code></pre><p>10、 检查已安装的fdupes版本。</p><pre tabindex=0><code>$ fdupes --version

fdupes 1.51
</code></pre><p>11、 如果你需要关于fdupes的帮助，可以使用<code>-h</code>开关。</p><pre tabindex=0><code>$ fdupes -h

Usage: fdupes [options] DIRECTORY...

 -r --recurse       for every directory given follow subdirectories
                    encountered within
 -R --recurse:      for each directory given after this option follow
                    subdirectories encountered within (note the &#39;:&#39; at
                    the end of the option, manpage for more details)
 -s --symlinks      follow symlinks
 -H --hardlinks     normally, when two or more files point to the same
                    disk area they are treated as non-duplicates; this
                    option will change this behavior
 -n --noempty       exclude zero-length files from consideration
 -A --nohidden      exclude hidden files from consideration
 -f --omitfirst     omit the first file in each set of matches
 -1 --sameline      list each set of matches on a single line
 -S --size          show size of duplicate files
 -m --summarize     summarize dupe information
 -q --quiet         hide progress indicator
 -d --delete        prompt user for files to preserve and delete all
                    others; important: under particular circumstances,
                    data may be lost when using this option together
                    with -s or --symlinks, or when specifying a
                    particular directory more than once; refer to the
                    fdupes documentation for additional information
 -N --noprompt      together with --delete, preserve the first file in
                    each set of duplicates and delete the rest without
                    prompting the user
 -v --version       display fdupes version
 -h --help          display this help message
</code></pre><p>到此为止了。让我知道你以前怎么在Linux中查找并删除重复文件的吧？同时，也让我知道你关于这个工具的看法。在下面的评论部分中提供你有价值的反馈吧，别忘了为我们点赞并分享，帮助我们扩散哦。</p><p>我正在使用另外一个移除重复文件的工具，它叫<strong>fslint</strong>。很快就会把使用心得分享给大家哦，你们一定会喜欢看的。</p><hr><p>via: <a href=http://www.tecmint.com/fdupes-find-and-delete-duplicate-files-in-linux/>http://www.tecmint.com/fdupes-find-and-delete-duplicate-files-in-linux/</a></p><p>作者：<a href=https://github.com/GOLinux>GOLinux</a> 校对：<a href=https://github.com/wxy>wxy</a></p><p>本文由 <a href=https://github.com/LCTT/TranslateProject>LCTT</a> 原创翻译，<a href=http://linux.cn/>Linux中国</a> 荣誉推出</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/fdupes/ rel=tag>fdupes</a></li><li class=tags__item><a class="tags__link btn" href=/tags/%E9%87%8D%E5%A4%8D/ rel=tag>重复</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Linux.cn Archive.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>